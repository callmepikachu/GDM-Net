"""
ä¿®å¤DDPæœªä½¿ç”¨å‚æ•°é—®é¢˜
è§£å†³å¤šGPUè®­ç»ƒä¸­çš„å‚æ•°åŒæ­¥é”™è¯¯
"""

import torch
import os
import sys


def analyze_unused_parameters():
    """åˆ†ææœªä½¿ç”¨çš„å‚æ•°"""
    print("ğŸ” åˆ†æDDPæœªä½¿ç”¨å‚æ•°é—®é¢˜...")
    
    # ä»é”™è¯¯ä¿¡æ¯ä¸­æå–çš„æœªä½¿ç”¨å‚æ•°ç´¢å¼•
    unused_params_rank0 = [207, 208, 209, 210, 217, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 270, 271]
    unused_params_rank1 = [207, 208, 209, 210, 217, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 270, 271]
    
    print(f"ğŸ“Š Rank 0 æœªä½¿ç”¨å‚æ•°: {len(unused_params_rank0)} ä¸ª")
    print(f"ğŸ“Š Rank 1 æœªä½¿ç”¨å‚æ•°: {len(unused_params_rank1)} ä¸ª")
    print(f"ğŸ¯ å‚æ•°ç´¢å¼•èŒƒå›´: {min(unused_params_rank0)} - {max(unused_params_rank0)}")
    
    # è¿™äº›å‚æ•°å¯èƒ½æ¥è‡ªï¼š
    print("\nğŸ’¡ å¯èƒ½çš„æœªä½¿ç”¨å‚æ•°æ¥æº:")
    print("  - å›¾è®°å¿†æ¨¡å—çš„æŸäº›å±‚")
    print("  - æ¨ç†æ¨¡å—çš„æŸäº›ç»„ä»¶")
    print("  - æ¡ä»¶æ€§ä½¿ç”¨çš„å‚æ•°ï¼ˆå½“å›¾ä¸ºç©ºæ—¶ï¼‰")


def setup_ddp_debug_env():
    """è®¾ç½®DDPè°ƒè¯•ç¯å¢ƒ"""
    print("ğŸ”§ è®¾ç½®DDPè°ƒè¯•ç¯å¢ƒ...")
    
    # DDPè°ƒè¯•ç¯å¢ƒå˜é‡
    debug_env = {
        'TORCH_DISTRIBUTED_DEBUG': 'DETAIL',
        'NCCL_DEBUG': 'INFO',
        'CUDA_LAUNCH_BLOCKING': '1',  # åŒæ­¥æ‰§è¡Œä»¥ä¾¿è°ƒè¯•
        'TORCH_SHOW_CPP_STACKTRACES': '1',
        'TORCH_USE_CUDA_DSA': '1'
    }
    
    for key, value in debug_env.items():
        os.environ[key] = value
        print(f"  {key} = {value}")
    
    print("âœ… DDPè°ƒè¯•ç¯å¢ƒè®¾ç½®å®Œæˆ")


def create_ddp_safe_config():
    """åˆ›å»ºDDPå®‰å…¨é…ç½®"""
    print("ğŸ“ åˆ›å»ºDDPå®‰å…¨é…ç½®...")
    
    safe_config = """
# DDP Safe Configuration
# ä¸“é—¨è§£å†³æœªä½¿ç”¨å‚æ•°é—®é¢˜çš„é…ç½®

seed: 42

model:
  bert_model_name: "bert-base-uncased"
  hidden_size: 768
  num_entities: 9
  num_relations: 10
  num_classes: 5
  gnn_type: "rgcn"
  num_gnn_layers: 2
  num_reasoning_hops: 3
  fusion_method: "gate"
  learning_rate: 2e-5
  dropout_rate: 0.1

data:
  train_path: "data/hotpotqa_official_train.json"
  val_path: "data/hotpotqa_official_val.json"
  test_path: "data/hotpotqa_official_val.json"
  max_length: 384  # é€‚ä¸­çš„åºåˆ—é•¿åº¦
  max_query_length: 64

training:
  max_epochs: 5
  batch_size: 2  # è¾ƒå°çš„æ‰¹æ¬¡å¤§å°ç¡®ä¿ç¨³å®šæ€§
  num_workers: 0  # ç¦ç”¨å¤šè¿›ç¨‹é¿å…å¤æ‚æ€§
  accelerator: "gpu"
  devices: 2  # ä½¿ç”¨2ä¸ªGPU
  strategy: "ddp_find_unused_parameters_true"  # å¯ç”¨æœªä½¿ç”¨å‚æ•°æ£€æµ‹
  precision: 32
  gradient_clip_val: 1.0
  accumulate_grad_batches: 2
  val_check_interval: 0.5
  log_every_n_steps: 10
  checkpoint_dir: "checkpoints"
  early_stopping: true
  patience: 3
  sync_batchnorm: true  # åŒæ­¥æ‰¹å½’ä¸€åŒ–

logging:
  type: "tensorboard"
  save_dir: "logs"
  name: "gdmnet-ddp-safe"
"""
    
    with open('config/ddp_safe_config.yaml', 'w') as f:
        f.write(safe_config.strip())
    
    print("âœ… DDPå®‰å…¨é…ç½®å·²åˆ›å»º: config/ddp_safe_config.yaml")


def test_model_forward():
    """æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­"""
    print("ğŸ§ª æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­...")
    
    try:
        from gdmnet import GDMNet
        
        # åˆ›å»ºæ¨¡å‹
        model = GDMNet(
            bert_model_name='bert-base-uncased',
            hidden_size=768,
            num_entities=9,
            num_relations=10,
            num_classes=5
        )
        
        model.eval()
        
        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        batch_size = 2
        seq_len = 128
        
        input_ids = torch.randint(0, 1000, (batch_size, seq_len))
        attention_mask = torch.ones(batch_size, seq_len)
        query = torch.randint(0, 1000, (batch_size, 32))
        entity_labels = torch.randint(0, 9, (batch_size, seq_len))
        relation_labels = torch.randint(0, 10, (batch_size, seq_len))
        
        # å‰å‘ä¼ æ’­
        with torch.no_grad():
            outputs = model(
                input_ids=input_ids,
                attention_mask=attention_mask,
                query=query,
                entity_labels=entity_labels,
                relation_labels=relation_labels
            )
        
        print("âœ… æ¨¡å‹å‰å‘ä¼ æ’­æµ‹è¯•æˆåŠŸ")
        print(f"  è¾“å‡ºå½¢çŠ¶: {outputs['logits'].shape}")
        
        # æ£€æŸ¥æ‰€æœ‰å‚æ•°æ˜¯å¦æœ‰æ¢¯åº¦
        model.train()
        outputs = model(
            input_ids=input_ids,
            attention_mask=attention_mask,
            query=query,
            entity_labels=entity_labels,
            relation_labels=relation_labels
        )
        
        loss = outputs['loss']
        loss.backward()
        
        # ç»Ÿè®¡æœ‰æ¢¯åº¦çš„å‚æ•°
        params_with_grad = 0
        params_without_grad = 0
        
        for name, param in model.named_parameters():
            if param.grad is not None:
                params_with_grad += 1
            else:
                params_without_grad += 1
                print(f"  æ— æ¢¯åº¦å‚æ•°: {name}")
        
        print(f"ğŸ“Š å‚æ•°æ¢¯åº¦ç»Ÿè®¡:")
        print(f"  æœ‰æ¢¯åº¦: {params_with_grad}")
        print(f"  æ— æ¢¯åº¦: {params_without_grad}")
        
        if params_without_grad == 0:
            print("âœ… æ‰€æœ‰å‚æ•°éƒ½æœ‰æ¢¯åº¦")
            return True
        else:
            print("âš ï¸ å­˜åœ¨æ— æ¢¯åº¦å‚æ•°")
            return False
            
    except Exception as e:
        print(f"âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        return False


def comprehensive_ddp_fix():
    """ç»¼åˆDDPé—®é¢˜ä¿®å¤"""
    print("ğŸ› ï¸ DDPæœªä½¿ç”¨å‚æ•°é—®é¢˜ç»¼åˆä¿®å¤")
    print("=" * 50)
    
    # 1. åˆ†æé—®é¢˜
    analyze_unused_parameters()
    print()
    
    # 2. è®¾ç½®è°ƒè¯•ç¯å¢ƒ
    setup_ddp_debug_env()
    print()
    
    # 3. åˆ›å»ºå®‰å…¨é…ç½®
    create_ddp_safe_config()
    print()
    
    # 4. æµ‹è¯•æ¨¡å‹
    model_ok = test_model_forward()
    print()
    
    # 5. ç»™å‡ºå»ºè®®
    if model_ok:
        print("ğŸ‰ æ¨¡å‹æµ‹è¯•é€šè¿‡ï¼")
        print("ğŸ’¡ å»ºè®®:")
        print("1. ä½¿ç”¨DDPå®‰å…¨é…ç½®é‡æ–°è®­ç»ƒ:")
        print("   python train/train.py --config config/ddp_safe_config.yaml --mode train")
        print("2. ç›‘æ§DDPè°ƒè¯•è¾“å‡º")
        print("3. å¦‚æœä»æœ‰é—®é¢˜ï¼Œåˆ‡æ¢åˆ°å•GPUæ¨¡å¼")
    else:
        print("âš ï¸ æ¨¡å‹ä»æœ‰é—®é¢˜")
        print("ğŸ’¡ å»ºè®®:")
        print("1. æ£€æŸ¥æ¨¡å‹ä»£ç ä¸­çš„æ¡ä»¶åˆ†æ”¯")
        print("2. ç¡®ä¿æ‰€æœ‰å‚æ•°éƒ½å‚ä¸å‰å‘ä¼ æ’­")
        print("3. ä½¿ç”¨å•GPUæ¨¡å¼ä½œä¸ºå¤‡é€‰")
    
    return model_ok


def quick_single_gpu_switch():
    """å¿«é€Ÿåˆ‡æ¢åˆ°å•GPUæ¨¡å¼"""
    print("âš¡ å¿«é€Ÿåˆ‡æ¢åˆ°å•GPUæ¨¡å¼")
    
    # å¼ºåˆ¶å•GPU
    os.environ['CUDA_VISIBLE_DEVICES'] = '0'
    
    print("âœ… å·²åˆ‡æ¢åˆ°å•GPUæ¨¡å¼")
    print("ğŸ’¡ ä½¿ç”¨å‘½ä»¤:")
    print("python train/train.py --config config/single_gpu_fallback_config.yaml --mode train")


if __name__ == "__main__":
    if len(sys.argv) > 1 and sys.argv[1] == '--single-gpu':
        quick_single_gpu_switch()
    else:
        success = comprehensive_ddp_fix()
        
        if not success:
            print("\nâš¡ å»ºè®®åˆ‡æ¢åˆ°å•GPUæ¨¡å¼...")
            quick_single_gpu_switch()
