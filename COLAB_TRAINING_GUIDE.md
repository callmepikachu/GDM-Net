# GDM-Net Google Colab è®­ç»ƒæŒ‡å—

æœ¬æŒ‡å—å°†å¸®åŠ©æ‚¨åœ¨Google Colabä¸Šè®­ç»ƒGDM-Netæ¨¡å‹ï¼Œå……åˆ†åˆ©ç”¨å…è´¹çš„GPUèµ„æºã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. æ‰“å¼€Google Colab

è®¿é—® [Google Colab](https://colab.research.google.com/) å¹¶åˆ›å»ºæ–°çš„ç¬”è®°æœ¬ã€‚

### 2. æ£€æŸ¥GPUå¯ç”¨æ€§

```python
# æ£€æŸ¥GPU
import torch
print(f"CUDA available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"GPU: {torch.cuda.get_device_name(0)}")
    print(f"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
else:
    print("No GPU available, using CPU")

# æ£€æŸ¥ç³»ç»Ÿä¿¡æ¯
!nvidia-smi
```

### 3. å®‰è£…ä¾èµ–

```python
# å®‰è£…å¿…è¦çš„åŒ…
!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
!pip install torch-geometric
!pip install transformers>=4.20.0
!pip install pytorch-lightning>=1.7.0
!pip install datasets>=2.0.0
!pip install PyYAML>=6.0
!pip install tensorboard>=2.8.0
!pip install wandb>=0.12.0
!pip install tqdm>=4.64.0
!pip install scikit-learn>=1.1.0
!pip install matplotlib>=3.5.0
!pip install seaborn>=0.11.0

print("âœ… ä¾èµ–å®‰è£…å®Œæˆ")
```

### 4. å…‹éš†æˆ–ä¸Šä¼ é¡¹ç›®ä»£ç 

```python
# æ–¹æ³•1: ä»GitHubå…‹éš†ï¼ˆå¦‚æœæ‚¨çš„ä»£ç åœ¨GitHubä¸Šï¼‰
# !git clone https://github.com/your-username/GDM-Net.git
# %cd GDM-Net

# æ–¹æ³•2: ä¸Šä¼ ä»£ç æ–‡ä»¶
# ä½¿ç”¨Colabçš„æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½ä¸Šä¼ æ‚¨çš„é¡¹ç›®æ–‡ä»¶

# æ–¹æ³•3: ä»Google DriveæŒ‚è½½
from google.colab import drive
drive.mount('/content/drive')

# å¦‚æœä»£ç åœ¨Google Driveä¸­
# %cd /content/drive/MyDrive/GDM-Net

print("âœ… é¡¹ç›®ä»£ç å‡†å¤‡å®Œæˆ")
```

## ğŸ“ é¡¹ç›®ç»“æ„è®¾ç½®

```python
# åˆ›å»ºé¡¹ç›®ç›®å½•ç»“æ„
import os

# åˆ›å»ºå¿…è¦çš„ç›®å½•
directories = [
    'gdmnet',
    'train', 
    'config',
    'data',
    'checkpoints',
    'logs',
    'examples'
]

for dir_name in directories:
    os.makedirs(dir_name, exist_ok=True)
    print(f"âœ… åˆ›å»ºç›®å½•: {dir_name}")
```

## ğŸ”§ Colabä¼˜åŒ–é…ç½®

```python
# åˆ›å»ºColabä¼˜åŒ–çš„é…ç½®æ–‡ä»¶
colab_config = """
# GDM-Net Colab Configuration - GPU Optimized

seed: 42

model:
  bert_model_name: "bert-base-uncased"
  hidden_size: 768
  num_entities: 8
  num_relations: 4
  num_classes: 5
  gnn_type: "rgcn"
  num_gnn_layers: 2
  num_reasoning_hops: 3
  fusion_method: "gate"
  learning_rate: 2e-5
  dropout_rate: 0.1

data:
  train_path: "data/hotpotqa_train.json"
  val_path: "data/hotpotqa_val.json"
  test_path: "data/hotpotqa_val.json"
  max_length: 512
  max_query_length: 64

training:
  max_epochs: 10
  batch_size: 8  # GPUå¯ä»¥ä½¿ç”¨æ›´å¤§çš„batch size
  num_workers: 2  # Colabæ¨èå€¼
  accelerator: "gpu"
  devices: 1
  precision: 16  # æ··åˆç²¾åº¦è®­ç»ƒï¼ŒèŠ‚çœGPUå†…å­˜
  gradient_clip_val: 1.0
  accumulate_grad_batches: 1
  val_check_interval: 0.5  # æ¯åŠä¸ªepochéªŒè¯ä¸€æ¬¡
  log_every_n_steps: 50
  checkpoint_dir: "checkpoints"
  early_stopping: true
  patience: 3

logging:
  type: "tensorboard"
  save_dir: "logs"
  name: "gdmnet-colab"
"""

# ä¿å­˜é…ç½®æ–‡ä»¶
with open('config/colab_config.yaml', 'w') as f:
    f.write(colab_config)

print("âœ… Colabé…ç½®æ–‡ä»¶åˆ›å»ºå®Œæˆ")
```

## ğŸ“Š æ•°æ®å‡†å¤‡

```python
# ä¸‹è½½å’Œå‡†å¤‡HotpotQAæ•°æ®é›†
import json
import requests
from tqdm import tqdm

def download_hotpotqa_data():
    """ä¸‹è½½HotpotQAæ•°æ®é›†"""
    
    # å¦‚æœæ‚¨å·²ç»æœ‰æ•°æ®æ–‡ä»¶ï¼Œå¯ä»¥è·³è¿‡ä¸‹è½½
    if os.path.exists('data/hotpotqa_train.json'):
        print("âœ… æ•°æ®æ–‡ä»¶å·²å­˜åœ¨")
        return
    
    print("ğŸ“¥ ä¸‹è½½HotpotQAæ•°æ®é›†...")
    
    # è¿™é‡Œä½¿ç”¨æ‚¨å·²ç»å‡†å¤‡å¥½çš„æ•°æ®
    # æˆ–è€…ä»æ‚¨çš„Google Driveå¤åˆ¶
    
    # ç¤ºä¾‹ï¼šä»Driveå¤åˆ¶æ•°æ®
    if os.path.exists('/content/drive/MyDrive/GDM-Net/data/'):
        !cp -r /content/drive/MyDrive/GDM-Net/data/* ./data/
        print("âœ… ä»Google Driveå¤åˆ¶æ•°æ®å®Œæˆ")
    else:
        print("âš ï¸ è¯·ä¸Šä¼ æ•°æ®æ–‡ä»¶åˆ°data/ç›®å½•")

# æ‰§è¡Œæ•°æ®å‡†å¤‡
download_hotpotqa_data()

# æ£€æŸ¥æ•°æ®
if os.path.exists('data/hotpotqa_train.json'):
    with open('data/hotpotqa_train.json', 'r') as f:
        data = json.load(f)
    print(f"ğŸ“Š è®­ç»ƒæ•°æ®: {len(data)} æ ·æœ¬")
    
    # æ˜¾ç¤ºæ•°æ®æ ·æœ¬
    print("ğŸ“‹ æ•°æ®æ ·æœ¬:")
    sample = data[0]
    print(f"æ–‡æ¡£: {sample['document'][:100]}...")
    print(f"æŸ¥è¯¢: {sample['query']}")
    print(f"å®ä½“æ•°é‡: {len(sample['entities'])}")
    print(f"å…³ç³»æ•°é‡: {len(sample['relations'])}")
```

## ğŸ§  æ¨¡å‹ä»£ç éƒ¨ç½²

```python
# å¦‚æœéœ€è¦ç›´æ¥åœ¨Colabä¸­å®šä¹‰æ¨¡å‹ä»£ç 
# è¿™é‡Œå¯ä»¥å¤åˆ¶æ‚¨çš„gdmnetæ¨¡å—ä»£ç 

# æˆ–è€…ä»æ–‡ä»¶å¯¼å…¥
import sys
sys.path.append('/content')  # æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„

# æµ‹è¯•å¯¼å…¥
try:
    from gdmnet import GDMNet
    print("âœ… GDM-Netæ¨¡å‹å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ æ¨¡å‹å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿æ‰€æœ‰æ¨¡å‹æ–‡ä»¶éƒ½å·²ä¸Šä¼ ")
```

## ğŸ‹ï¸ å¼€å§‹è®­ç»ƒ

```python
# è®¾ç½®è®­ç»ƒç¯å¢ƒ
import os
os.environ['TOKENIZERS_PARALLELISM'] = 'false'  # é¿å…tokenizerè­¦å‘Š

# å¼€å§‹è®­ç»ƒ
!python train/train.py --config config/colab_config.yaml --mode train

print("ğŸ‰ è®­ç»ƒå¯åŠ¨å®Œæˆï¼")
```

## ğŸ“ˆ ç›‘æ§è®­ç»ƒè¿›åº¦

```python
# åœ¨æ–°çš„cellä¸­è¿è¡ŒTensorBoard
%load_ext tensorboard
%tensorboard --logdir logs/

# æˆ–è€…ä½¿ç”¨å‘½ä»¤è¡Œ
# !tensorboard --logdir logs/ --host 0.0.0.0 --port 6006
```

```python
# å®æ—¶æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
import time
import glob

def monitor_training():
    """ç›‘æ§è®­ç»ƒè¿›åº¦"""
    while True:
        # æ£€æŸ¥æœ€æ–°çš„æ—¥å¿—æ–‡ä»¶
        log_files = glob.glob('logs/gdmnet-colab/version_*/events.out.tfevents.*')
        if log_files:
            latest_log = max(log_files, key=os.path.getctime)
            print(f"ğŸ“Š æœ€æ–°æ—¥å¿—: {latest_log}")
        
        # æ£€æŸ¥æ£€æŸ¥ç‚¹
        checkpoints = glob.glob('checkpoints/*.ckpt')
        if checkpoints:
            latest_ckpt = max(checkpoints, key=os.path.getctime)
            print(f"ğŸ’¾ æœ€æ–°æ£€æŸ¥ç‚¹: {latest_ckpt}")
        
        time.sleep(30)  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡

# åœ¨åå°è¿è¡Œç›‘æ§ï¼ˆå¯é€‰ï¼‰
# monitor_training()
```

## ğŸ’¾ ä¿å­˜å’Œä¸‹è½½ç»“æœ

```python
# è®­ç»ƒå®Œæˆåï¼Œä¿å­˜é‡è¦æ–‡ä»¶åˆ°Google Drive
def save_results_to_drive():
    """ä¿å­˜è®­ç»ƒç»“æœåˆ°Google Drive"""
    
    # åˆ›å»ºç»“æœç›®å½•
    result_dir = '/content/drive/MyDrive/GDM-Net-Results'
    os.makedirs(result_dir, exist_ok=True)
    
    # å¤åˆ¶æ£€æŸ¥ç‚¹
    !cp -r checkpoints/* /content/drive/MyDrive/GDM-Net-Results/
    
    # å¤åˆ¶æ—¥å¿—
    !cp -r logs/* /content/drive/MyDrive/GDM-Net-Results/
    
    print("âœ… ç»“æœå·²ä¿å­˜åˆ°Google Drive")

# ä¸‹è½½æœ€ä½³æ¨¡å‹
def download_best_model():
    """ä¸‹è½½æœ€ä½³æ¨¡å‹åˆ°æœ¬åœ°"""
    import glob
    from google.colab import files
    
    # æ‰¾åˆ°æœ€ä½³æ£€æŸ¥ç‚¹
    checkpoints = glob.glob('checkpoints/*.ckpt')
    if checkpoints:
        best_model = min(checkpoints, key=lambda x: float(x.split('val_loss=')[1].split('-')[0]))
        print(f"ğŸ“¥ ä¸‹è½½æœ€ä½³æ¨¡å‹: {best_model}")
        files.download(best_model)
    else:
        print("âŒ æœªæ‰¾åˆ°æ£€æŸ¥ç‚¹æ–‡ä»¶")

# æ‰§è¡Œä¿å­˜
save_results_to_drive()
```

## ğŸ§ª æ¨¡å‹æµ‹è¯•å’Œæ¨ç†

```python
# åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæµ‹è¯•
import torch
from gdmnet import GDMNet

def test_trained_model():
    """æµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹"""
    
    # æ‰¾åˆ°æœ€ä½³æ£€æŸ¥ç‚¹
    import glob
    checkpoints = glob.glob('checkpoints/*.ckpt')
    if not checkpoints:
        print("âŒ æœªæ‰¾åˆ°æ£€æŸ¥ç‚¹æ–‡ä»¶")
        return
    
    best_model_path = min(checkpoints, key=lambda x: float(x.split('val_loss=')[1].split('-')[0]))
    print(f"ğŸ§  åŠ è½½æ¨¡å‹: {best_model_path}")
    
    # åŠ è½½æ¨¡å‹
    model = GDMNet.load_from_checkpoint(best_model_path)
    model.eval()
    
    print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    print(f"ğŸ“Š æ¨¡å‹å‚æ•°: {sum(p.numel() for p in model.parameters()):,}")
    
    return model

# æµ‹è¯•æ¨¡å‹
trained_model = test_trained_model()
```

```python
# è¿è¡Œæ¨ç†ç¤ºä¾‹
def run_inference_example(model):
    """è¿è¡Œæ¨ç†ç¤ºä¾‹"""
    from transformers import BertTokenizer
    
    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
    
    # ç¤ºä¾‹è¾“å…¥
    document = "Apple Inc. is a technology company founded by Steve Jobs. Tim Cook is the current CEO."
    query = "Who is the CEO of Apple?"
    
    # ç¼–ç è¾“å…¥
    doc_encoding = tokenizer(
        document,
        max_length=512,
        padding='max_length',
        truncation=True,
        return_tensors='pt'
    )
    
    query_encoding = tokenizer(
        query,
        max_length=64,
        padding='max_length', 
        truncation=True,
        return_tensors='pt'
    )
    
    # æ¨ç†
    with torch.no_grad():
        if torch.cuda.is_available():
            model = model.cuda()
            doc_encoding = {k: v.cuda() for k, v in doc_encoding.items()}
            query_encoding = {k: v.cuda() for k, v in query_encoding.items()}
        
        outputs = model(
            input_ids=doc_encoding['input_ids'],
            attention_mask=doc_encoding['attention_mask'],
            query=query_encoding['input_ids']
        )
    
    # æ˜¾ç¤ºç»“æœ
    prediction = torch.argmax(outputs, dim=-1)
    confidence = torch.softmax(outputs, dim=-1).max()
    
    print(f"ğŸ¯ é¢„æµ‹ç»“æœ: {prediction.item()}")
    print(f"ğŸ“Š ç½®ä¿¡åº¦: {confidence.item():.3f}")

# è¿è¡Œæ¨ç†
if 'trained_model' in locals():
    run_inference_example(trained_model)
```

## âš ï¸ Colabæ³¨æ„äº‹é¡¹

### 1. ä¼šè¯ç®¡ç†
```python
# é˜²æ­¢ä¼šè¯è¶…æ—¶
import time
from IPython.display import Javascript

def keep_alive():
    """ä¿æŒColabä¼šè¯æ´»è·ƒ"""
    display(Javascript('''
        function ClickConnect(){
            console.log("Working");
            document.querySelector("colab-toolbar-button#connect").click()
        }
        setInterval(ClickConnect,60000)
    '''))

# è¿è¡Œä¿æ´»è„šæœ¬ï¼ˆå¯é€‰ï¼‰
# keep_alive()
```

### 2. å†…å­˜ç®¡ç†
```python
# æ¸…ç†GPUå†…å­˜
import gc
import torch

def clear_memory():
    """æ¸…ç†å†…å­˜"""
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    print("âœ… å†…å­˜æ¸…ç†å®Œæˆ")

# åœ¨éœ€è¦æ—¶è°ƒç”¨
clear_memory()
```

### 3. æ£€æŸ¥ç‚¹æ¢å¤
```python
# ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ
def resume_training():
    """ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ"""
    import glob
    
    checkpoints = glob.glob('checkpoints/*.ckpt')
    if checkpoints:
        latest_ckpt = max(checkpoints, key=os.path.getctime)
        print(f"ğŸ”„ ä»æ£€æŸ¥ç‚¹æ¢å¤: {latest_ckpt}")
        
        # ä¿®æ”¹è®­ç»ƒå‘½ä»¤ä»¥åŒ…å«resume_from_checkpoint
        !python train/train.py --config config/colab_config.yaml --mode train --resume_from_checkpoint {latest_ckpt}
    else:
        print("âŒ æœªæ‰¾åˆ°æ£€æŸ¥ç‚¹ï¼Œå¼€å§‹æ–°çš„è®­ç»ƒ")
        !python train/train.py --config config/colab_config.yaml --mode train

# å¦‚æœéœ€è¦æ¢å¤è®­ç»ƒ
# resume_training()
```

## ğŸ‰ å®Œæ•´è®­ç»ƒæµç¨‹

å°†ä»¥ä¸Šæ‰€æœ‰ä»£ç æŒ‰é¡ºåºåœ¨Colabä¸­æ‰§è¡Œï¼Œæ‚¨å°±å¯ä»¥æˆåŠŸåœ¨GPUä¸Šè®­ç»ƒGDM-Netæ¨¡å‹äº†ï¼

### é¢„æœŸæ€§èƒ½
- **GPUè®­ç»ƒé€Ÿåº¦**: æ¯”CPUå¿«10-20å€
- **å†…å­˜ä½¿ç”¨**: çº¦4-6GB GPUå†…å­˜
- **è®­ç»ƒæ—¶é—´**: å®Œæ•´æ•°æ®é›†çº¦1-2å°æ—¶

### æœ€ç»ˆæ£€æŸ¥æ¸…å•
- âœ… GPUå¯ç”¨æ€§ç¡®è®¤
- âœ… ä¾èµ–åŒ…å®‰è£…
- âœ… æ•°æ®é›†å‡†å¤‡
- âœ… æ¨¡å‹ä»£ç éƒ¨ç½²
- âœ… é…ç½®æ–‡ä»¶ä¼˜åŒ–
- âœ… è®­ç»ƒå¯åŠ¨
- âœ… è¿›åº¦ç›‘æ§
- âœ… ç»“æœä¿å­˜

ç¥æ‚¨è®­ç»ƒé¡ºåˆ©ï¼ğŸš€
