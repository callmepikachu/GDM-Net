{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMxyz123"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 🧠 GDM-Net Google Colab 训练\n",
        "\n",
        "Graph-Augmented Dual Memory Network for Multi-Document Understanding\n",
        "\n",
        "本笔记本将帮助您在Google Colab上训练GDM-Net模型。\n",
        "\n",
        "## 📋 使用前准备\n",
        "1. 确保选择了GPU运行时：Runtime → Change runtime type → GPU\n",
        "2. 准备好您的数据文件\n",
        "3. 上传项目代码文件"
      ],
      "metadata": {
        "id": "title_cell"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🔧 1. 环境检查和设置"
      ],
      "metadata": {
        "id": "setup_title"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 检查GPU可用性\n",
        "import torch\n",
        "import os\n",
        "\n",
        "print(\"🔍 系统信息检查\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "    print(f\"PyTorch version: {torch.__version__}\")\n",
        "else:\n",
        "    print(\"⚠️ No GPU available, using CPU\")\n",
        "\n",
        "# 显示详细GPU信息\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "check_gpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 安装依赖包\n",
        "print(\"📦 安装依赖包...\")\n",
        "\n",
        "# 安装PyTorch和相关包\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install torch-geometric\n",
        "!pip install transformers>=4.20.0\n",
        "!pip install pytorch-lightning>=1.7.0\n",
        "!pip install datasets>=2.0.0\n",
        "!pip install PyYAML>=6.0\n",
        "!pip install tensorboard>=2.8.0\n",
        "!pip install wandb>=0.12.0\n",
        "!pip install tqdm>=4.64.0\n",
        "!pip install scikit-learn>=1.1.0\n",
        "!pip install matplotlib>=3.5.0\n",
        "!pip install seaborn>=0.11.0\n",
        "\n",
        "print(\"✅ 依赖安装完成\")"
      ],
      "metadata": {
        "id": "install_deps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📁 2. 项目文件准备"
      ],
      "metadata": {
        "id": "files_title"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 挂载Google Drive（可选）\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 如果您的项目文件在Google Drive中，可以复制到Colab\n",
        "# !cp -r /content/drive/MyDrive/GDM-Net/* /content/\n",
        "\n",
        "print(\"✅ Google Drive 挂载完成\")"
      ],
      "metadata": {
        "id": "mount_drive"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 创建项目目录结构\n",
        "import os\n",
        "\n",
        "directories = [\n",
        "    'gdmnet',\n",
        "    'train', \n",
        "    'config',\n",
        "    'data',\n",
        "    'checkpoints',\n",
        "    'logs',\n",
        "    'examples'\n",
        "]\n",
        "\n",
        "for dir_name in directories:\n",
        "    os.makedirs(dir_name, exist_ok=True)\n",
        "    print(f\"✅ 创建目录: {dir_name}\")\n",
        "\n",
        "print(\"\\n📁 项目结构创建完成\")"
      ],
      "metadata": {
        "id": "create_dirs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ⚙️ 3. 配置文件创建"
      ],
      "metadata": {
        "id": "config_title"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 创建Colab优化的配置文件\n",
        "colab_config = \"\"\"\n",
        "# GDM-Net Colab Configuration - GPU Optimized\n",
        "\n",
        "seed: 42\n",
        "\n",
        "model:\n",
        "  bert_model_name: \"bert-base-uncased\"\n",
        "  hidden_size: 768\n",
        "  num_entities: 8\n",
        "  num_relations: 4\n",
        "  num_classes: 5\n",
        "  gnn_type: \"rgcn\"\n",
        "  num_gnn_layers: 2\n",
        "  num_reasoning_hops: 3\n",
        "  fusion_method: \"gate\"\n",
        "  learning_rate: 2e-5\n",
        "  dropout_rate: 0.1\n",
        "\n",
        "data:\n",
        "  train_path: \"data/hotpotqa_train.json\"\n",
        "  val_path: \"data/hotpotqa_val.json\"\n",
        "  test_path: \"data/hotpotqa_val.json\"\n",
        "  max_length: 512\n",
        "  max_query_length: 64\n",
        "\n",
        "training:\n",
        "  max_epochs: 10\n",
        "  batch_size: 8\n",
        "  num_workers: 2\n",
        "  accelerator: \"gpu\"\n",
        "  devices: 1\n",
        "  precision: 16\n",
        "  gradient_clip_val: 1.0\n",
        "  accumulate_grad_batches: 1\n",
        "  val_check_interval: 0.5\n",
        "  log_every_n_steps: 50\n",
        "  checkpoint_dir: \"checkpoints\"\n",
        "  early_stopping: true\n",
        "  patience: 3\n",
        "\n",
        "logging:\n",
        "  type: \"tensorboard\"\n",
        "  save_dir: \"logs\"\n",
        "  name: \"gdmnet-colab\"\n",
        "\"\"\"\n",
        "\n",
        "# 保存配置文件\n",
        "with open('config/colab_config.yaml', 'w') as f:\n",
        "    f.write(colab_config.strip())\n",
        "\n",
        "print(\"✅ Colab配置文件创建完成\")\n",
        "print(\"📄 配置文件路径: config/colab_config.yaml\")"
      ],
      "metadata": {
        "id": "create_config"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📊 4. 数据准备\n",
        "\n",
        "**请上传您的数据文件到 `data/` 目录，或从Google Drive复制。**"
      ],
      "metadata": {
        "id": "data_title"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 检查数据文件\n",
        "import json\n",
        "import os\n",
        "\n",
        "def check_data_files():\n",
        "    \"\"\"检查数据文件是否存在\"\"\"\n",
        "    data_files = [\n",
        "        'data/hotpotqa_train.json',\n",
        "        'data/hotpotqa_val.json'\n",
        "    ]\n",
        "    \n",
        "    for file_path in data_files:\n",
        "        if os.path.exists(file_path):\n",
        "            with open(file_path, 'r') as f:\n",
        "                data = json.load(f)\n",
        "            print(f\"✅ {file_path}: {len(data)} 样本\")\n",
        "            \n",
        "            # 显示样本\n",
        "            if data:\n",
        "                sample = data[0]\n",
        "                print(f\"   文档: {sample['document'][:100]}...\")\n",
        "                print(f\"   查询: {sample['query']}\")\n",
        "                print(f\"   实体: {len(sample['entities'])}, 关系: {len(sample['relations'])}\")\n",
        "                print()\n",
        "        else:\n",
        "            print(f\"❌ {file_path}: 文件不存在\")\n",
        "\n",
        "# 检查数据\n",
        "check_data_files()\n",
        "\n",
        "# 如果没有数据文件，提供上传选项\n",
        "if not os.path.exists('data/hotpotqa_train.json'):\n",
        "    print(\"\\n📤 请上传数据文件:\")\n",
        "    print(\"1. 使用左侧文件面板上传到 data/ 目录\")\n",
        "    print(\"2. 或从Google Drive复制:\")\n",
        "    print(\"   !cp /content/drive/MyDrive/path/to/your/data/* ./data/\")"
      ],
      "metadata": {
        "id": "check_data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🧠 5. 模型代码部署\n",
        "\n",
        "**请确保已上传所有GDM-Net模型文件到对应目录。**"
      ],
      "metadata": {
        "id": "model_title"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 检查模型文件\n",
        "import sys\n",
        "sys.path.append('/content')\n",
        "\n",
        "def check_model_files():\n",
        "    \"\"\"检查模型文件是否存在\"\"\"\n",
        "    required_files = [\n",
        "        'gdmnet/__init__.py',\n",
        "        'gdmnet/model.py',\n",
        "        'gdmnet/encoder.py',\n",
        "        'gdmnet/extractor.py',\n",
        "        'gdmnet/graph_memory.py',\n",
        "        'gdmnet/reasoning.py',\n",
        "        'train/train.py',\n",
        "        'train/dataset.py'\n",
        "    ]\n",
        "    \n",
        "    all_exist = True\n",
        "    for file_path in required_files:\n",
        "        if os.path.exists(file_path):\n",
        "            print(f\"✅ {file_path}\")\n",
        "        else:\n",
        "            print(f\"❌ {file_path}\")\n",
        "            all_exist = False\n",
        "    \n",
        "    return all_exist\n",
        "\n",
        "# 检查文件\n",
        "files_ok = check_model_files()\n",
        "\n",
        "if files_ok:\n",
        "    # 测试导入\n",
        "    try:\n",
        "        from gdmnet import GDMNet\n",
        "        print(\"\\n✅ GDM-Net模型导入成功\")\n",
        "    except ImportError as e:\n",
        "        print(f\"\\n❌ 模型导入失败: {e}\")\n",
        "else:\n",
        "    print(\"\\n❌ 缺少必要的模型文件，请上传完整的项目代码\")"
      ],
      "metadata": {
        "id": "check_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🏋️ 6. 开始训练"
      ],
      "metadata": {
        "id": "training_title"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 设置训练环境\n",
        "import os\n",
        "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
        "\n",
        "# 开始训练\n",
        "print(\"🚀 启动GDM-Net训练...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "!python train/train.py --config config/colab_config.yaml --mode train\n",
        "\n",
        "print(\"\\n🎉 训练完成！\")"
      ],
      "metadata": {
        "id": "start_training"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📈 7. 监控训练进度"
      ],
      "metadata": {
        "id": "monitor_title"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 启动TensorBoard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs/\n",
        "\n",
        "print(\"📊 TensorBoard已启动，您可以在上方看到训练曲线\")"
      ],
      "metadata": {
        "id": "tensorboard"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 检查训练进度\n",
        "import glob\n",
        "import os\n",
        "\n",
        "def check_training_progress():\n",
        "    \"\"\"检查训练进度\"\"\"\n",
        "    print(\"📊 训练进度检查\")\n",
        "    print(\"=\" * 30)\n",
        "    \n",
        "    # 检查检查点\n",
        "    checkpoints = glob.glob('checkpoints/*.ckpt')\n",
        "    if checkpoints:\n",
        "        print(f\"💾 找到 {len(checkpoints)} 个检查点:\")\n",
        "        for ckpt in sorted(checkpoints):\n",
        "            size = os.path.getsize(ckpt) / (1024*1024)\n",
        "            print(f\"   {os.path.basename(ckpt)} ({size:.1f} MB)\")\n",
        "        \n",
        "        # 找到最佳模型\n",
        "        best_model = min(checkpoints, key=lambda x: float(x.split('val_loss=')[1].split('-')[0]))\n",
        "        print(f\"\\n🏆 最佳模型: {os.path.basename(best_model)}\")\n",
        "    else:\n",
        "        print(\"❌ 未找到检查点文件\")\n",
        "    \n",
        "    # 检查日志\n",
        "    log_dirs = glob.glob('logs/gdmnet-colab/version_*')\n",
        "    if log_dirs:\n",
        "        print(f\"\\n📋 找到 {len(log_dirs)} 个日志目录\")\n",
        "    else:\n",
        "        print(\"\\n❌ 未找到日志目录\")\n",
        "\n",
        "# 检查进度\n",
        "check_training_progress()"
      ],
      "metadata": {
        "id": "check_progress"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🧪 8. 模型测试和推理"
      ],
      "metadata": {
        "id": "inference_title"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 加载训练好的模型\n",
        "import torch\n",
        "import glob\n",
        "from gdmnet import GDMNet\n",
        "\n",
        "def load_best_model():\n",
        "    \"\"\"加载最佳模型\"\"\"\n",
        "    checkpoints = glob.glob('checkpoints/*.ckpt')\n",
        "    if not checkpoints:\n",
        "        print(\"❌ 未找到检查点文件\")\n",
        "        return None\n",
        "    \n",
        "    # 找到验证损失最低的模型\n",
        "    best_model_path = min(checkpoints, key=lambda x: float(x.split('val_loss=')[1].split('-')[0]))\n",
        "    print(f\"🧠 加载最佳模型: {best_model_path}\")\n",
        "    \n",
        "    # 加载模型\n",
        "    model = GDMNet.load_from_checkpoint(best_model_path)\n",
        "    model.eval()\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "        model = model.cuda()\n",
        "        print(\"🔥 模型已移至GPU\")\n",
        "    \n",
        "    print(f\"✅ 模型加载成功\")\n",
        "    print(f\"📊 模型参数: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "    \n",
        "    return model\n",
        "\n",
        "# 加载模型\n",
        "trained_model = load_best_model()"
      ],
      "metadata": {
        "id": "load_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 运行推理示例\n",
        "from transformers import BertTokenizer\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def run_inference_demo(model):\n",
        "    \"\"\"运行推理演示\"\"\"\n",
        "    if model is None:\n",
        "        print(\"❌ 模型未加载\")\n",
        "        return\n",
        "    \n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    \n",
        "    # 示例输入\n",
        "    examples = [\n",
        "        {\n",
        "            \"document\": \"Apple Inc. is a technology company founded by Steve Jobs. Tim Cook is the current CEO.\",\n",
        "            \"query\": \"Who is the CEO of Apple?\"\n",
        "        },\n",
        "        {\n",
        "            \"document\": \"Microsoft Corporation was founded by Bill Gates. Satya Nadella is the current CEO.\",\n",
        "            \"query\": \"Who founded Microsoft?\"\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    print(\"🔍 推理演示\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    for i, example in enumerate(examples, 1):\n",
        "        print(f\"\\n📋 示例 {i}:\")\n",
        "        print(f\"文档: {example['document']}\")\n",
        "        print(f\"查询: {example['query']}\")\n",
        "        \n",
        "        # 编码输入\n",
        "        doc_encoding = tokenizer(\n",
        "            example['document'],\n",
        "            max_length=512,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        \n",
        "        query_encoding = tokenizer(\n",
        "            example['query'],\n",
        "            max_length=64,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        \n",
        "        # 移至GPU（如果可用）\n",
        "        if torch.cuda.is_available():\n",
        "            doc_encoding = {k: v.cuda() for k, v in doc_encoding.items()}\n",
        "            query_encoding = {k: v.cuda() for k, v in query_encoding.items()}\n",
        "        \n",
        "        # 推理\n",
        "        with torch.no_grad():\n",
        "            outputs = model(\n",
        "                input_ids=doc_encoding['input_ids'],\n",
        "                attention_mask=doc_encoding['attention_mask'],\n",
        "                query=query_encoding['input_ids'],\n",
        "                return_intermediate=True\n",
        "            )\n",
        "        \n",
        "        # 显示结果\n",
        "        logits = outputs['logits']\n",
        "        probabilities = F.softmax(logits, dim=-1)\n",
        "        prediction = torch.argmax(logits, dim=-1)\n",
        "        confidence = probabilities.max()\n",
        "        \n",
        "        print(f\"🎯 预测类别: {prediction.item()}\")\n",
        "        print(f\"📊 置信度: {confidence.item():.3f}\")\n",
        "        print(f\"🔍 提取实体: {len(outputs['entities'][0])}\")\n",
        "        print(f\"🔗 提取关系: {len(outputs['relations'][0])}\")\n",
        "\n",
        "# 运行推理演示\n",
        "if 'trained_model' in locals() and trained_model is not None:\n",
        "    run_inference_demo(trained_model)\n",
        "else:\n",
        "    print(\"⚠️ 请先加载训练好的模型\")"
      ],
      "metadata": {
        "id": "inference_demo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 💾 9. 保存和下载结果"
      ],
      "metadata": {
        "id": "save_title"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 保存结果到Google Drive\n",
        "def save_to_drive():\n",
        "    \"\"\"保存训练结果到Google Drive\"\"\"\n",
        "    result_dir = '/content/drive/MyDrive/GDM-Net-Results'\n",
        "    os.makedirs(result_dir, exist_ok=True)\n",
        "    \n",
        "    print(\"💾 保存结果到Google Drive...\")\n",
        "    \n",
        "    # 复制检查点\n",
        "    if os.path.exists('checkpoints'):\n",
        "        !cp -r checkpoints/* /content/drive/MyDrive/GDM-Net-Results/\n",
        "        print(\"✅ 检查点已保存\")\n",
        "    \n",
        "    # 复制日志\n",
        "    if os.path.exists('logs'):\n",
        "        !cp -r logs/* /content/drive/MyDrive/GDM-Net-Results/\n",
        "        print(\"✅ 日志已保存\")\n",
        "    \n",
        "    # 保存配置\n",
        "    !cp config/colab_config.yaml /content/drive/MyDrive/GDM-Net-Results/\n",
        "    print(\"✅ 配置文件已保存\")\n",
        "    \n",
        "    print(f\"\\n🎉 所有结果已保存到: {result_dir}\")\n",
        "\n",
        "# 执行保存\n",
        "save_to_drive()"
      ],
      "metadata": {
        "id": "save_results"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 下载最佳模型到本地\n",
        "from google.colab import files\n",
        "import glob\n",
        "\n",
        "def download_best_model():\n",
        "    \"\"\"下载最佳模型\"\"\"\n",
        "    checkpoints = glob.glob('checkpoints/*.ckpt')\n",
        "    if checkpoints:\n",
        "        best_model = min(checkpoints, key=lambda x: float(x.split('val_loss=')[1].split('-')[0]))\n",
        "        print(f\"📥 下载最佳模型: {best_model}\")\n",
        "        files.download(best_model)\n",
        "        print(\"✅ 下载完成\")\n",
        "    else:\n",
        "        print(\"❌ 未找到检查点文件\")\n",
        "\n",
        "# 下载模型（可选）\n",
        "# download_best_model()"
      ],
      "metadata": {
        "id": "download_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🎉 训练完成！\n",
        "\n",
        "恭喜您成功在Google Colab上训练了GDM-Net模型！\n",
        "\n",
        "### 📋 后续步骤：\n",
        "1. 查看TensorBoard中的训练曲线\n",
        "2. 使用训练好的模型进行推理\n",
        "3. 保存重要结果到Google Drive\n",
        "4. 下载最佳模型到本地\n",
        "\n",
        "### 🔧 进一步优化：\n",
        "- 调整超参数（学习率、批次大小等）\n",
        "- 尝试不同的融合策略\n",
        "- 使用更大的数据集\n",
        "- 实验不同的GNN架构\n",
        "\n",
        "### 📞 获取帮助：\n",
        "如果遇到问题，请检查：\n",
        "1. GPU是否正确启用\n",
        "2. 所有依赖是否正确安装\n",
        "3. 数据文件格式是否正确\n",
        "4. 模型文件是否完整上传\n",
        "\n",
        "祝您研究顺利！🚀"
      ],
      "metadata": {
        "id": "conclusion"
      }
    }
  ]
}
