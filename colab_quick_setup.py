"""
Google Colab å¿«é€Ÿè®¾ç½®è„šæœ¬
ä¸€é”®å®Œæˆç¯å¢ƒé…ç½®å’Œè®­ç»ƒå‡†å¤‡
"""

import os
import json
import subprocess
import sys


def install_dependencies():
    """å®‰è£…ä¾èµ–åŒ…"""
    print("ğŸ“¦ å®‰è£…ä¾èµ–åŒ…...")
    
    packages = [
        "torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118",
        "torch-geometric",
        "transformers>=4.20.0",
        "pytorch-lightning>=1.7.0",
        "datasets>=2.0.0",
        "PyYAML>=6.0",
        "tensorboard>=2.8.0",
        "wandb>=0.12.0",
        "tqdm>=4.64.0",
        "scikit-learn>=1.1.0",
        "matplotlib>=3.5.0",
        "seaborn>=0.11.0"
    ]
    
    for package in packages:
        try:
            subprocess.run([sys.executable, "-m", "pip", "install"] + package.split(), 
                         check=True, capture_output=True)
            print(f"âœ… {package.split()[0]}")
        except subprocess.CalledProcessError as e:
            print(f"âŒ {package.split()[0]}: {e}")
    
    print("âœ… ä¾èµ–å®‰è£…å®Œæˆ")


def check_gpu():
    """æ£€æŸ¥GPUå¯ç”¨æ€§"""
    print("ğŸ” æ£€æŸ¥GPU...")
    
    try:
        import torch
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            print(f"âœ… GPU: {gpu_name}")
            print(f"âœ… GPU Memory: {gpu_memory:.1f} GB")
            return True
        else:
            print("âš ï¸ No GPU available")
            return False
    except ImportError:
        print("âŒ PyTorch not installed")
        return False


def create_directories():
    """åˆ›å»ºé¡¹ç›®ç›®å½•"""
    print("ğŸ“ åˆ›å»ºé¡¹ç›®ç›®å½•...")
    
    directories = [
        'gdmnet', 'train', 'config', 'data', 
        'checkpoints', 'logs', 'examples'
    ]
    
    for dir_name in directories:
        os.makedirs(dir_name, exist_ok=True)
        print(f"âœ… {dir_name}/")


def create_colab_config():
    """åˆ›å»ºColabä¼˜åŒ–é…ç½®"""
    print("âš™ï¸ åˆ›å»ºé…ç½®æ–‡ä»¶...")
    
    config = {
        'seed': 42,
        'model': {
            'bert_model_name': 'bert-base-uncased',
            'hidden_size': 768,
            'num_entities': 8,
            'num_relations': 4,
            'num_classes': 5,
            'gnn_type': 'rgcn',
            'num_gnn_layers': 2,
            'num_reasoning_hops': 3,
            'fusion_method': 'gate',
            'learning_rate': 2e-5,
            'dropout_rate': 0.1
        },
        'data': {
            'train_path': 'data/hotpotqa_train.json',
            'val_path': 'data/hotpotqa_val.json',
            'test_path': 'data/hotpotqa_val.json',
            'max_length': 512,
            'max_query_length': 64
        },
        'training': {
            'max_epochs': 10,
            'batch_size': 8,
            'num_workers': 2,
            'accelerator': 'gpu',
            'devices': 1,
            'precision': 16,
            'gradient_clip_val': 1.0,
            'accumulate_grad_batches': 1,
            'val_check_interval': 0.5,
            'log_every_n_steps': 50,
            'checkpoint_dir': 'checkpoints',
            'early_stopping': True,
            'patience': 3
        },
        'logging': {
            'type': 'tensorboard',
            'save_dir': 'logs',
            'name': 'gdmnet-colab'
        }
    }
    
    import yaml
    with open('config/colab_config.yaml', 'w') as f:
        yaml.dump(config, f, default_flow_style=False)
    
    print("âœ… é…ç½®æ–‡ä»¶: config/colab_config.yaml")


def create_sample_data():
    """åˆ›å»ºç¤ºä¾‹æ•°æ®ï¼ˆå¦‚æœæ²¡æœ‰çœŸå®æ•°æ®ï¼‰"""
    print("ğŸ“Š åˆ›å»ºç¤ºä¾‹æ•°æ®...")
    
    if os.path.exists('data/hotpotqa_train.json'):
        print("âœ… è®­ç»ƒæ•°æ®å·²å­˜åœ¨")
        return
    
    # åˆ›å»ºæœ€å°ç¤ºä¾‹æ•°æ®
    sample_data = []
    for i in range(20):
        sample = {
            "document": f"This is sample document {i}. It contains information about topic {i}.",
            "query": f"What is the main topic of document {i}?",
            "entities": [
                {"span": [0, 4], "type": 0, "text": "This"},
                {"span": [8, 14], "type": 1, "text": "sample"}
            ],
            "relations": [
                {"head": 0, "tail": 1, "type": 0}
            ],
            "label": i % 5,
            "metadata": {"source": "sample", "id": f"sample_{i}"}
        }
        sample_data.append(sample)
    
    # ä¿å­˜è®­ç»ƒå’ŒéªŒè¯æ•°æ®
    train_data = sample_data[:16]
    val_data = sample_data[16:]
    
    with open('data/hotpotqa_train.json', 'w') as f:
        json.dump(train_data, f, indent=2)
    
    with open('data/hotpotqa_val.json', 'w') as f:
        json.dump(val_data, f, indent=2)
    
    print(f"âœ… ç¤ºä¾‹æ•°æ®: {len(train_data)} è®­ç»ƒ, {len(val_data)} éªŒè¯")


def check_files():
    """æ£€æŸ¥å¿…è¦æ–‡ä»¶"""
    print("ğŸ” æ£€æŸ¥é¡¹ç›®æ–‡ä»¶...")
    
    required_files = [
        'gdmnet/__init__.py',
        'gdmnet/model.py',
        'train/train.py',
        'config/colab_config.yaml',
        'data/hotpotqa_train.json'
    ]
    
    missing_files = []
    for file_path in required_files:
        if os.path.exists(file_path):
            print(f"âœ… {file_path}")
        else:
            print(f"âŒ {file_path}")
            missing_files.append(file_path)
    
    if missing_files:
        print(f"\nâš ï¸ ç¼ºå°‘ {len(missing_files)} ä¸ªæ–‡ä»¶")
        print("è¯·ä¸Šä¼ å®Œæ•´çš„é¡¹ç›®ä»£ç ")
        return False
    else:
        print("âœ… æ‰€æœ‰å¿…è¦æ–‡ä»¶éƒ½å­˜åœ¨")
        return True


def show_next_steps():
    """æ˜¾ç¤ºåç»­æ­¥éª¤"""
    print("\nğŸ‰ Colabç¯å¢ƒè®¾ç½®å®Œæˆï¼")
    print("=" * 50)
    print("ğŸ“‹ åç»­æ­¥éª¤:")
    print("1. ä¸Šä¼ é¡¹ç›®ä»£ç æ–‡ä»¶ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰")
    print("2. ä¸Šä¼ çœŸå®æ•°æ®æ–‡ä»¶åˆ° data/ ç›®å½•")
    print("3. è¿è¡Œè®­ç»ƒ:")
    print("   !python train/train.py --config config/colab_config.yaml --mode train")
    print("4. ç›‘æ§è®­ç»ƒ:")
    print("   %load_ext tensorboard")
    print("   %tensorboard --logdir logs/")
    print("\nğŸš€ å¼€å§‹æ‚¨çš„GDM-Netè®­ç»ƒä¹‹æ—…ï¼")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§  GDM-Net Google Colab å¿«é€Ÿè®¾ç½®")
    print("=" * 60)
    
    # æ‰§è¡Œè®¾ç½®æ­¥éª¤
    install_dependencies()
    print()
    
    check_gpu()
    print()
    
    create_directories()
    print()
    
    create_colab_config()
    print()
    
    create_sample_data()
    print()
    
    files_ok = check_files()
    print()
    
    show_next_steps()
    
    return files_ok


if __name__ == "__main__":
    main()
