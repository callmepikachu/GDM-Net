"""
è°ƒè¯•æ•°æ®é›†é—®é¢˜
æ£€æŸ¥å®ä½“å’Œå…³ç³»ç±»å‹çš„èŒƒå›´
"""

import json
import numpy as np


def analyze_dataset(filepath):
    """åˆ†ææ•°æ®é›†ä¸­çš„å®ä½“å’Œå…³ç³»ç±»å‹"""
    print(f"ğŸ“Š åˆ†ææ•°æ®é›†: {filepath}")
    
    with open(filepath, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    entity_types = []
    relation_types = []
    labels = []
    
    for item in data:
        # æ”¶é›†å®ä½“ç±»å‹
        for entity in item.get('entities', []):
            if isinstance(entity.get('type'), int):
                entity_types.append(entity['type'])
            elif isinstance(entity.get('type'), str):
                # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è½¬æ¢
                try:
                    entity_types.append(hash(entity['type']) % 10)  # ç®€å•å“ˆå¸Œåˆ°0-9
                except:
                    entity_types.append(0)
        
        # æ”¶é›†å…³ç³»ç±»å‹
        for relation in item.get('relations', []):
            if isinstance(relation.get('type'), int):
                relation_types.append(relation['type'])
            elif isinstance(relation.get('type'), str):
                try:
                    relation_types.append(hash(relation['type']) % 10)  # ç®€å•å“ˆå¸Œåˆ°0-9
                except:
                    relation_types.append(0)
        
        # æ”¶é›†æ ‡ç­¾
        labels.append(item.get('label', 0))
    
    print(f"å®ä½“ç±»å‹èŒƒå›´: {min(entity_types) if entity_types else 'N/A'} - {max(entity_types) if entity_types else 'N/A'}")
    print(f"å…³ç³»ç±»å‹èŒƒå›´: {min(relation_types) if relation_types else 'N/A'} - {max(relation_types) if relation_types else 'N/A'}")
    print(f"æ ‡ç­¾èŒƒå›´: {min(labels)} - {max(labels)}")
    print(f"å”¯ä¸€å®ä½“ç±»å‹: {sorted(set(entity_types)) if entity_types else []}")
    print(f"å”¯ä¸€å…³ç³»ç±»å‹: {sorted(set(relation_types)) if relation_types else []}")
    print(f"å”¯ä¸€æ ‡ç­¾: {sorted(set(labels))}")
    
    return {
        'max_entity_type': max(entity_types) if entity_types else 0,
        'max_relation_type': max(relation_types) if relation_types else 0,
        'max_label': max(labels),
        'entity_types': sorted(set(entity_types)) if entity_types else [],
        'relation_types': sorted(set(relation_types)) if relation_types else [],
        'labels': sorted(set(labels))
    }


def fix_dataset(filepath, output_path, max_entity_type=7, max_relation_type=9):
    """ä¿®å¤æ•°æ®é›†ä¸­çš„ç±»å‹ç´¢å¼•é—®é¢˜"""
    print(f"ğŸ”§ ä¿®å¤æ•°æ®é›†: {filepath}")
    
    with open(filepath, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    fixed_data = []
    
    for item in data:
        fixed_item = item.copy()
        
        # ä¿®å¤å®ä½“ç±»å‹
        fixed_entities = []
        for entity in item.get('entities', []):
            fixed_entity = entity.copy()
            entity_type = entity.get('type', 0)
            
            if isinstance(entity_type, str):
                # å­—ç¬¦ä¸²ç±»å‹æ˜ å°„
                type_mapping = {
                    'TITLE': 1,
                    'ENTITY': 2,
                    'PERSON': 3,
                    'ORGANIZATION': 4,
                    'LOCATION': 5,
                    'MISC': 6
                }
                fixed_entity['type'] = type_mapping.get(entity_type, 0)
            elif isinstance(entity_type, int):
                # ç¡®ä¿åœ¨èŒƒå›´å†…
                fixed_entity['type'] = min(entity_type, max_entity_type)
            else:
                fixed_entity['type'] = 0
            
            fixed_entities.append(fixed_entity)
        
        fixed_item['entities'] = fixed_entities
        
        # ä¿®å¤å…³ç³»ç±»å‹
        fixed_relations = []
        for relation in item.get('relations', []):
            fixed_relation = relation.copy()
            relation_type = relation.get('type', 0)
            
            if isinstance(relation_type, str):
                # å­—ç¬¦ä¸²ç±»å‹æ˜ å°„
                type_mapping = {
                    'SUPPORTS': 1,
                    'RELATED': 2,
                    'PART_OF': 3,
                    'LOCATED_IN': 4
                }
                fixed_relation['type'] = type_mapping.get(relation_type, 0)
            elif isinstance(relation_type, int):
                # ç¡®ä¿åœ¨èŒƒå›´å†…
                fixed_relation['type'] = min(relation_type, max_relation_type)
            else:
                fixed_relation['type'] = 0
            
            fixed_relations.append(fixed_relation)
        
        fixed_item['relations'] = fixed_relations
        
        # ç¡®ä¿æ ‡ç­¾åœ¨åˆç†èŒƒå›´å†…
        fixed_item['label'] = min(item.get('label', 0), 4)
        
        fixed_data.append(fixed_item)
    
    # ä¿å­˜ä¿®å¤åçš„æ•°æ®
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(fixed_data, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… ä¿®å¤å®Œæˆ: {output_path} ({len(fixed_data)} æ ·æœ¬)")
    return output_path


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” æ•°æ®é›†è°ƒè¯•å·¥å…·")
    print("=" * 40)
    
    # åˆ†ææ•°æ®é›†
    datasets = [
        'data/hotpotqa_small_train.json',
        'data/hotpotqa_small_val.json'
    ]
    
    max_entity = 0
    max_relation = 0
    
    for dataset in datasets:
        try:
            stats = analyze_dataset(dataset)
            max_entity = max(max_entity, stats['max_entity_type'])
            max_relation = max(max_relation, stats['max_relation_type'])
            print()
        except Exception as e:
            print(f"âŒ åˆ†æå¤±è´¥ {dataset}: {e}")
    
    print(f"ğŸ“‹ å»ºè®®çš„æ¨¡å‹é…ç½®:")
    print(f"num_entities: {max_entity + 1}")
    print(f"num_relations: {max_relation + 1}")
    
    # ä¿®å¤æ•°æ®é›†
    print(f"\nğŸ”§ ä¿®å¤æ•°æ®é›†...")
    for dataset in datasets:
        try:
            output_path = dataset.replace('.json', '_fixed.json')
            fix_dataset(dataset, output_path, max_entity_type=7, max_relation_type=9)
        except Exception as e:
            print(f"âŒ ä¿®å¤å¤±è´¥ {dataset}: {e}")


if __name__ == "__main__":
    main()
