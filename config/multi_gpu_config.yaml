# Multi-GPU Configuration for GDM-Net
# 针对多GPU环境优化的配置

seed: 42

model:
  bert_model_name: "bert-base-uncased"
  hidden_size: 768
  num_entities: 9
  num_relations: 10
  num_classes: 5
  gnn_type: "rgcn"
  num_gnn_layers: 2
  num_reasoning_hops: 3
  fusion_method: "gate"
  learning_rate: 2e-5
  dropout_rate: 0.1

data:
  train_path: "data/hotpotqa_official_train.json"
  val_path: "data/hotpotqa_official_val.json"
  test_path: "data/hotpotqa_official_val.json"
  max_length: 512  # 多GPU可以使用更长序列
  max_query_length: 64

training:
  max_epochs: 5
  batch_size: 4  # 每个GPU的批次大小
  num_workers: 4  # 多GPU可以使用更多worker
  accelerator: "gpu"
  devices: -1  # 使用所有可用GPU，代码会自动检测
  strategy: "ddp"  # 分布式数据并行
  precision: 32
  gradient_clip_val: 1.0
  accumulate_grad_batches: 1  # 多GPU不需要太多累积
  val_check_interval: 0.25
  log_every_n_steps: 50
  checkpoint_dir: "checkpoints"
  early_stopping: true
  patience: 3

logging:
  type: "tensorboard"
  save_dir: "logs"
  name: "gdmnet-multi-gpu"
