# High-Performance Single GPU Configuration
# Optimized for 48GB GPU memory - full model capacity

seed: 42

model:
  bert_model_name: "bert-base-uncased"
  hidden_size: 768  # 完整BERT隐藏层大小
  num_entities: 9
  num_relations: 10
  num_classes: 5
  gnn_type: "rgcn"
  num_gnn_layers: 3  # 增加GNN层数以提升性能
  num_reasoning_hops: 4  # 增加推理跳数
  fusion_method: "gate"
  dropout_rate: 0.2  # 增加dropout减少过拟合
  freeze_bert: true  # 冻结BERT参数，只训练下游任务层

data:
  train_path: "/root/autodl-fs/train.json"                 # 训练集路径 (90,447样本)
  val_path: "/root/autodl-fs/dev_distractor.json"          # 验证集路径 (7,405样本)
  test_path: "/root/autodl-fs/dev_fullwiki.json"           # 测试集路径
  max_length: 512  # 完整序列长度
  max_query_length: 64

training:
  max_epochs: 30  # 进一步增加训练轮数
  batch_size: 8   # 进一步减小batch size
  learning_rate: 2e-4  # 增加学习率适应更大batch size
  num_workers: 16  # 最大化数据加载并行度
  accelerator: "gpu"
  devices: 1
  precision: 32
  gradient_clip_val: 0.5  # 更严格的梯度裁剪
  accumulate_grad_batches: 1  # 减少梯度累积，因为batch size已增加
  val_check_interval: 0.5
  log_every_n_steps: 10  # 进一步减少日志频率
  checkpoint_dir: "checkpoints"
  early_stopping: true
  patience: 15  # 增加耐心值适应更长训练

logging:
  type: "tensorboard"
  save_dir: "logs"
  name: "gdmnet-high-performance"
