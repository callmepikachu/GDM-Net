"""
åˆ†å¸ƒå¼å›¾å­˜å‚¨æ¥å£ - æ”¯æŒå¤§è§„æ¨¡å›¾çš„åˆ†å¸ƒå¼å­˜å‚¨å’ŒæŸ¥è¯¢
"""

import os
import pickle
import hashlib
import json
from typing import Dict, List, Tuple, Any, Optional
from abc import ABC, abstractmethod
import numpy as np


class GraphStorageInterface(ABC):
    """å›¾å­˜å‚¨æ¥å£åŸºç±»"""
    
    @abstractmethod
    def store_node(self, node_id: str, node_data: Dict[str, Any]) -> bool:
        """å­˜å‚¨èŠ‚ç‚¹"""
        pass
    
    @abstractmethod
    def store_edge(self, src_id: str, dst_id: str, rel_type: int, edge_data: Dict[str, Any]) -> bool:
        """å­˜å‚¨è¾¹"""
        pass
    
    @abstractmethod
    def get_node(self, node_id: str) -> Optional[Dict[str, Any]]:
        """è·å–èŠ‚ç‚¹"""
        pass
    
    @abstractmethod
    def get_edges(self, node_id: str) -> List[Tuple[str, int, str, Dict[str, Any]]]:
        """è·å–èŠ‚ç‚¹çš„æ‰€æœ‰è¾¹"""
        pass
    
    @abstractmethod
    def query_nodes_by_type(self, node_type: str, limit: int = 100) -> List[Tuple[str, Dict[str, Any]]]:
        """æŒ‰ç±»å‹æŸ¥è¯¢èŠ‚ç‚¹"""
        pass
    
    @abstractmethod
    def query_similar_nodes(self, embedding: np.ndarray, top_k: int = 10) -> List[Tuple[str, Dict[str, Any], float]]:
        """æŸ¥è¯¢ç›¸ä¼¼èŠ‚ç‚¹"""
        pass


class ShardedFileStorage(GraphStorageInterface):
    """
    ğŸš€ åŸºäºæ–‡ä»¶çš„åˆ†ç‰‡å­˜å‚¨ - é€‚åˆä¸­ç­‰è§„æ¨¡çš„å›¾
    """
    
    def __init__(self, storage_dir: str, num_shards: int = 16):
        self.storage_dir = storage_dir
        self.num_shards = num_shards
        
        # åˆ›å»ºå­˜å‚¨ç›®å½•
        os.makedirs(storage_dir, exist_ok=True)
        for i in range(num_shards):
            os.makedirs(os.path.join(storage_dir, f"shard_{i}"), exist_ok=True)
        
        # å†…å­˜ç¼“å­˜
        self.node_cache = {}
        self.edge_cache = {}
        self.cache_size_limit = 10000
    
    def _get_shard_id(self, node_id: str) -> int:
        """æ ¹æ®èŠ‚ç‚¹IDè®¡ç®—åˆ†ç‰‡ID"""
        return int(hashlib.md5(node_id.encode()).hexdigest(), 16) % self.num_shards
    
    def _get_node_file_path(self, node_id: str) -> str:
        """è·å–èŠ‚ç‚¹æ–‡ä»¶è·¯å¾„"""
        shard_id = self._get_shard_id(node_id)
        return os.path.join(self.storage_dir, f"shard_{shard_id}", "nodes.pkl")
    
    def _get_edge_file_path(self, node_id: str) -> str:
        """è·å–è¾¹æ–‡ä»¶è·¯å¾„"""
        shard_id = self._get_shard_id(node_id)
        return os.path.join(self.storage_dir, f"shard_{shard_id}", "edges.pkl")
    
    def _load_shard_nodes(self, shard_id: int) -> Dict[str, Dict[str, Any]]:
        """åŠ è½½åˆ†ç‰‡çš„èŠ‚ç‚¹æ•°æ®"""
        file_path = os.path.join(self.storage_dir, f"shard_{shard_id}", "nodes.pkl")
        if os.path.exists(file_path):
            try:
                with open(file_path, 'rb') as f:
                    return pickle.load(f)
            except:
                return {}
        return {}
    
    def _save_shard_nodes(self, shard_id: int, nodes: Dict[str, Dict[str, Any]]):
        """ä¿å­˜åˆ†ç‰‡çš„èŠ‚ç‚¹æ•°æ®"""
        file_path = os.path.join(self.storage_dir, f"shard_{shard_id}", "nodes.pkl")
        with open(file_path, 'wb') as f:
            pickle.dump(nodes, f)
    
    def _load_shard_edges(self, shard_id: int) -> Dict[str, List[Tuple[str, int, str, Dict[str, Any]]]]:
        """åŠ è½½åˆ†ç‰‡çš„è¾¹æ•°æ®"""
        file_path = os.path.join(self.storage_dir, f"shard_{shard_id}", "edges.pkl")
        if os.path.exists(file_path):
            try:
                with open(file_path, 'rb') as f:
                    return pickle.load(f)
            except:
                return {}
        return {}
    
    def _save_shard_edges(self, shard_id: int, edges: Dict[str, List[Tuple[str, int, str, Dict[str, Any]]]]):
        """ä¿å­˜åˆ†ç‰‡çš„è¾¹æ•°æ®"""
        file_path = os.path.join(self.storage_dir, f"shard_{shard_id}", "edges.pkl")
        with open(file_path, 'wb') as f:
            pickle.dump(edges, f)
    
    def store_node(self, node_id: str, node_data: Dict[str, Any]) -> bool:
        """å­˜å‚¨èŠ‚ç‚¹"""
        try:
            shard_id = self._get_shard_id(node_id)
            
            # åŠ è½½åˆ†ç‰‡æ•°æ®
            shard_nodes = self._load_shard_nodes(shard_id)
            shard_nodes[node_id] = node_data
            
            # ä¿å­˜åˆ†ç‰‡æ•°æ®
            self._save_shard_nodes(shard_id, shard_nodes)
            
            # æ›´æ–°ç¼“å­˜
            self.node_cache[node_id] = node_data
            self._manage_cache_size()
            
            return True
        except Exception as e:
            print(f"âŒ Failed to store node {node_id}: {e}")
            return False
    
    def store_edge(self, src_id: str, dst_id: str, rel_type: int, edge_data: Dict[str, Any]) -> bool:
        """å­˜å‚¨è¾¹"""
        try:
            # è¾¹å­˜å‚¨åœ¨æºèŠ‚ç‚¹çš„åˆ†ç‰‡ä¸­
            shard_id = self._get_shard_id(src_id)
            
            # åŠ è½½åˆ†ç‰‡è¾¹æ•°æ®
            shard_edges = self._load_shard_edges(shard_id)
            
            if src_id not in shard_edges:
                shard_edges[src_id] = []
            
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒçš„è¾¹
            edge_tuple = (src_id, rel_type, dst_id, edge_data)
            existing_edges = shard_edges[src_id]
            
            # æ›´æ–°æˆ–æ·»åŠ è¾¹
            updated = False
            for i, (s, r, d, data) in enumerate(existing_edges):
                if s == src_id and r == rel_type and d == dst_id:
                    existing_edges[i] = edge_tuple
                    updated = True
                    break
            
            if not updated:
                existing_edges.append(edge_tuple)
            
            # ä¿å­˜åˆ†ç‰‡æ•°æ®
            self._save_shard_edges(shard_id, shard_edges)
            
            return True
        except Exception as e:
            print(f"âŒ Failed to store edge {src_id}->{dst_id}: {e}")
            return False
    
    def get_node(self, node_id: str) -> Optional[Dict[str, Any]]:
        """è·å–èŠ‚ç‚¹"""
        # å…ˆæ£€æŸ¥ç¼“å­˜
        if node_id in self.node_cache:
            return self.node_cache[node_id]
        
        try:
            shard_id = self._get_shard_id(node_id)
            shard_nodes = self._load_shard_nodes(shard_id)
            
            node_data = shard_nodes.get(node_id)
            if node_data:
                # æ›´æ–°ç¼“å­˜
                self.node_cache[node_id] = node_data
                self._manage_cache_size()
            
            return node_data
        except Exception as e:
            print(f"âŒ Failed to get node {node_id}: {e}")
            return None
    
    def get_edges(self, node_id: str) -> List[Tuple[str, int, str, Dict[str, Any]]]:
        """è·å–èŠ‚ç‚¹çš„æ‰€æœ‰è¾¹"""
        try:
            shard_id = self._get_shard_id(node_id)
            shard_edges = self._load_shard_edges(shard_id)
            
            return shard_edges.get(node_id, [])
        except Exception as e:
            print(f"âŒ Failed to get edges for {node_id}: {e}")
            return []
    
    def query_nodes_by_type(self, node_type: str, limit: int = 100) -> List[Tuple[str, Dict[str, Any]]]:
        """æŒ‰ç±»å‹æŸ¥è¯¢èŠ‚ç‚¹"""
        results = []
        
        try:
            for shard_id in range(self.num_shards):
                if len(results) >= limit:
                    break
                
                shard_nodes = self._load_shard_nodes(shard_id)
                
                for node_id, node_data in shard_nodes.items():
                    if len(results) >= limit:
                        break
                    
                    if node_data.get('type') == node_type:
                        results.append((node_id, node_data))
            
            return results[:limit]
        except Exception as e:
            print(f"âŒ Failed to query nodes by type {node_type}: {e}")
            return []
    
    def query_similar_nodes(self, embedding: np.ndarray, top_k: int = 10) -> List[Tuple[str, Dict[str, Any], float]]:
        """æŸ¥è¯¢ç›¸ä¼¼èŠ‚ç‚¹"""
        from sklearn.metrics.pairwise import cosine_similarity
        
        candidates = []
        
        try:
            for shard_id in range(self.num_shards):
                shard_nodes = self._load_shard_nodes(shard_id)
                
                for node_id, node_data in shard_nodes.items():
                    if 'embedding' in node_data:
                        node_embedding = np.array(node_data['embedding'])
                        similarity = cosine_similarity(
                            embedding.reshape(1, -1), 
                            node_embedding.reshape(1, -1)
                        )[0, 0]
                        candidates.append((node_id, node_data, similarity))
            
            # æŒ‰ç›¸ä¼¼åº¦æ’åºå¹¶è¿”å›top_k
            candidates.sort(key=lambda x: x[2], reverse=True)
            return candidates[:top_k]
            
        except Exception as e:
            print(f"âŒ Failed to query similar nodes: {e}")
            return []
    
    def _manage_cache_size(self):
        """ç®¡ç†ç¼“å­˜å¤§å°"""
        if len(self.node_cache) > self.cache_size_limit:
            # ç®€å•çš„LRUï¼šåˆ é™¤ä¸€åŠç¼“å­˜
            items = list(self.node_cache.items())
            self.node_cache = dict(items[len(items)//2:])
    
    def get_storage_stats(self) -> Dict[str, Any]:
        """è·å–å­˜å‚¨ç»Ÿè®¡ä¿¡æ¯"""
        total_nodes = 0
        total_edges = 0
        shard_sizes = []
        
        for shard_id in range(self.num_shards):
            try:
                shard_nodes = self._load_shard_nodes(shard_id)
                shard_edges = self._load_shard_edges(shard_id)
                
                shard_node_count = len(shard_nodes)
                shard_edge_count = sum(len(edges) for edges in shard_edges.values())
                
                total_nodes += shard_node_count
                total_edges += shard_edge_count
                shard_sizes.append({
                    'shard_id': shard_id,
                    'nodes': shard_node_count,
                    'edges': shard_edge_count
                })
            except:
                shard_sizes.append({
                    'shard_id': shard_id,
                    'nodes': 0,
                    'edges': 0
                })
        
        return {
            'total_nodes': total_nodes,
            'total_edges': total_edges,
            'num_shards': self.num_shards,
            'cache_size': len(self.node_cache),
            'shard_sizes': shard_sizes
        }


class DistributedGraphStorage:
    """
    ğŸš€ åˆ†å¸ƒå¼å›¾å­˜å‚¨ç®¡ç†å™¨ - ç»Ÿä¸€ç®¡ç†ä¸åŒçš„å­˜å‚¨åç«¯
    """
    
    def __init__(self, storage_type: str = "sharded_file", **kwargs):
        self.storage_type = storage_type
        
        if storage_type == "sharded_file":
            self.storage = ShardedFileStorage(**kwargs)
        else:
            raise ValueError(f"Unsupported storage type: {storage_type}")
    
    def migrate_from_memory(self, memory_data: Dict[str, Any]) -> bool:
        """
        ä»å†…å­˜æ•°æ®è¿ç§»åˆ°åˆ†å¸ƒå¼å­˜å‚¨
        Args:
            memory_data: å†…å­˜ä¸­çš„å›¾æ•°æ®
        Returns:
            bool: è¿ç§»æ˜¯å¦æˆåŠŸ
        """
        try:
            nodes = memory_data.get('nodes', {})
            edges = memory_data.get('edges', {})
            
            print(f"ğŸ”„ Migrating {len(nodes)} nodes and {len(edges)} edges...")
            
            # è¿ç§»èŠ‚ç‚¹
            for node_id, node_data in nodes.items():
                self.storage.store_node(node_id, node_data)
            
            # è¿ç§»è¾¹
            for (src, rel_type, dst), edge_data in edges.items():
                self.storage.store_edge(src, dst, rel_type, edge_data)
            
            print("âœ… Migration completed successfully")
            return True
            
        except Exception as e:
            print(f"âŒ Migration failed: {e}")
            return False
    
    def get_storage_interface(self) -> GraphStorageInterface:
        """è·å–å­˜å‚¨æ¥å£"""
        return self.storage
