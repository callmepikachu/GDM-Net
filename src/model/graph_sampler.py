"""
å›¾é‡‡æ ·å™¨ - ç”¨äºå¤§å›¾çš„é«˜æ•ˆé‡‡æ ·å’Œæ¨ç†ä¼˜åŒ–
"""

import torch
import numpy as np
from typing import List, Tuple, Set, Dict, Any
import random


class GraphSampler:
    """
    å›¾é‡‡æ ·å™¨ï¼Œæä¾›å¤šç§é‡‡æ ·ç­–ç•¥æ¥å¤„ç†å¤§è§„æ¨¡å›¾
    """
    
    def __init__(self, max_nodes: int = 200, max_edges: int = 500):
        self.max_nodes = max_nodes
        self.max_edges = max_edges
    
    def random_walk_sampling(self, 
                           node_features: torch.Tensor,
                           edge_index: torch.Tensor,
                           edge_type: torch.Tensor,
                           start_nodes: List[int],
                           walk_length: int = 3,
                           num_walks: int = 10) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, List[int]]:
        """
        ğŸš€ éšæœºæ¸¸èµ°é‡‡æ ·
        Args:
            node_features: èŠ‚ç‚¹ç‰¹å¾ [num_nodes, hidden_size]
            edge_index: è¾¹ç´¢å¼• [2, num_edges]
            edge_type: è¾¹ç±»å‹ [num_edges]
            start_nodes: èµ·å§‹èŠ‚ç‚¹åˆ—è¡¨
            walk_length: æ¸¸èµ°é•¿åº¦
            num_walks: æ¯ä¸ªèµ·å§‹èŠ‚ç‚¹çš„æ¸¸èµ°æ¬¡æ•°
        Returns:
            é‡‡æ ·åçš„å­å›¾ç»„ä»¶
        """
        if node_features.size(0) <= self.max_nodes:
            # å›¾å·²ç»è¶³å¤Ÿå°ï¼Œä¸éœ€è¦é‡‡æ ·
            return node_features, edge_index, edge_type, list(range(node_features.size(0)))
        
        # æ„å»ºé‚»æ¥è¡¨
        adj_list = self._build_adjacency_list(edge_index, node_features.size(0))
        
        # æ‰§è¡Œéšæœºæ¸¸èµ°
        sampled_nodes = set()
        for start_node in start_nodes:
            if start_node < len(adj_list):
                for _ in range(num_walks):
                    walk_nodes = self._random_walk(adj_list, start_node, walk_length)
                    sampled_nodes.update(walk_nodes)
        
        # å¦‚æœé‡‡æ ·èŠ‚ç‚¹å¤ªå°‘ï¼Œæ·»åŠ ä¸€äº›éšæœºèŠ‚ç‚¹
        if len(sampled_nodes) < self.max_nodes // 2:
            additional_nodes = random.sample(
                range(node_features.size(0)), 
                min(self.max_nodes - len(sampled_nodes), node_features.size(0) - len(sampled_nodes))
            )
            sampled_nodes.update(additional_nodes)
        
        # é™åˆ¶èŠ‚ç‚¹æ•°é‡
        if len(sampled_nodes) > self.max_nodes:
            sampled_nodes = set(random.sample(list(sampled_nodes), self.max_nodes))
        
        return self._extract_subgraph(node_features, edge_index, edge_type, sampled_nodes)
    
    def k_hop_sampling(self,
                      node_features: torch.Tensor,
                      edge_index: torch.Tensor, 
                      edge_type: torch.Tensor,
                      center_nodes: List[int],
                      k: int = 2) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, List[int]]:
        """
        ğŸš€ Kè·³é‚»å±…é‡‡æ ·
        Args:
            node_features: èŠ‚ç‚¹ç‰¹å¾
            edge_index: è¾¹ç´¢å¼•
            edge_type: è¾¹ç±»å‹
            center_nodes: ä¸­å¿ƒèŠ‚ç‚¹åˆ—è¡¨
            k: è·³æ•°
        Returns:
            é‡‡æ ·åçš„å­å›¾ç»„ä»¶
        """
        if node_features.size(0) <= self.max_nodes:
            return node_features, edge_index, edge_type, list(range(node_features.size(0)))
        
        # æ„å»ºé‚»æ¥è¡¨
        adj_list = self._build_adjacency_list(edge_index, node_features.size(0))
        
        # Kè·³é‚»å±…æœç´¢
        sampled_nodes = set(center_nodes)
        current_nodes = set(center_nodes)
        
        for hop in range(k):
            next_nodes = set()
            for node in current_nodes:
                if node < len(adj_list):
                    neighbors = adj_list[node]
                    # é™åˆ¶æ¯ä¸ªèŠ‚ç‚¹çš„é‚»å±…æ•°é‡
                    if len(neighbors) > 20:
                        neighbors = random.sample(neighbors, 20)
                    next_nodes.update(neighbors)
            
            sampled_nodes.update(next_nodes)
            current_nodes = next_nodes
            
            # å¦‚æœèŠ‚ç‚¹æ•°é‡è¶…è¿‡é™åˆ¶ï¼Œæå‰åœæ­¢
            if len(sampled_nodes) > self.max_nodes:
                break
        
        # é™åˆ¶èŠ‚ç‚¹æ•°é‡
        if len(sampled_nodes) > self.max_nodes:
            # ä¼˜å…ˆä¿ç•™ä¸­å¿ƒèŠ‚ç‚¹å’Œå®ƒä»¬çš„ç›´æ¥é‚»å±…
            priority_nodes = set(center_nodes)
            for center in center_nodes:
                if center < len(adj_list):
                    priority_nodes.update(adj_list[center][:10])  # æ¯ä¸ªä¸­å¿ƒèŠ‚ç‚¹ä¿ç•™10ä¸ªé‚»å±…
            
            remaining_quota = self.max_nodes - len(priority_nodes)
            other_nodes = sampled_nodes - priority_nodes
            
            if remaining_quota > 0 and other_nodes:
                additional_nodes = random.sample(list(other_nodes), min(remaining_quota, len(other_nodes)))
                priority_nodes.update(additional_nodes)
            
            sampled_nodes = priority_nodes
        
        return self._extract_subgraph(node_features, edge_index, edge_type, sampled_nodes)
    
    def importance_sampling(self,
                          node_features: torch.Tensor,
                          edge_index: torch.Tensor,
                          edge_type: torch.Tensor,
                          node_importance: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, List[int]]:
        """
        ğŸš€ åŸºäºé‡è¦æ€§çš„é‡‡æ ·
        Args:
            node_features: èŠ‚ç‚¹ç‰¹å¾
            edge_index: è¾¹ç´¢å¼•
            edge_type: è¾¹ç±»å‹
            node_importance: èŠ‚ç‚¹é‡è¦æ€§åˆ†æ•° [num_nodes]
        Returns:
            é‡‡æ ·åçš„å­å›¾ç»„ä»¶
        """
        if node_features.size(0) <= self.max_nodes:
            return node_features, edge_index, edge_type, list(range(node_features.size(0)))
        
        # æ ¹æ®é‡è¦æ€§åˆ†æ•°é‡‡æ ·
        _, top_indices = torch.topk(node_importance, min(self.max_nodes, len(node_importance)))
        sampled_nodes = set(top_indices.tolist())
        
        return self._extract_subgraph(node_features, edge_index, edge_type, sampled_nodes)
    
    def _build_adjacency_list(self, edge_index: torch.Tensor, num_nodes: int) -> List[List[int]]:
        """æ„å»ºé‚»æ¥è¡¨"""
        adj_list = [[] for _ in range(num_nodes)]
        
        for i in range(edge_index.size(1)):
            src, dst = edge_index[0, i].item(), edge_index[1, i].item()
            if src < num_nodes and dst < num_nodes:
                adj_list[src].append(dst)
                adj_list[dst].append(src)  # æ— å‘å›¾
        
        return adj_list
    
    def _random_walk(self, adj_list: List[List[int]], start_node: int, walk_length: int) -> List[int]:
        """æ‰§è¡Œå•æ¬¡éšæœºæ¸¸èµ°"""
        walk = [start_node]
        current_node = start_node
        
        for _ in range(walk_length):
            if current_node >= len(adj_list) or not adj_list[current_node]:
                break
            
            next_node = random.choice(adj_list[current_node])
            walk.append(next_node)
            current_node = next_node
        
        return walk
    
    def _extract_subgraph(self, 
                         node_features: torch.Tensor,
                         edge_index: torch.Tensor,
                         edge_type: torch.Tensor,
                         sampled_nodes: Set[int]) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, List[int]]:
        """ä»é‡‡æ ·èŠ‚ç‚¹ä¸­æå–å­å›¾"""
        sampled_nodes_list = sorted(list(sampled_nodes))
        node_mapping = {old_id: new_id for new_id, old_id in enumerate(sampled_nodes_list)}
        
        # æå–èŠ‚ç‚¹ç‰¹å¾
        sampled_node_features = node_features[sampled_nodes_list]
        
        # æå–è¾¹
        sampled_edges = []
        sampled_edge_types = []
        
        for i in range(edge_index.size(1)):
            src, dst = edge_index[0, i].item(), edge_index[1, i].item()
            if src in sampled_nodes and dst in sampled_nodes:
                new_src = node_mapping[src]
                new_dst = node_mapping[dst]
                sampled_edges.append([new_src, new_dst])
                sampled_edge_types.append(edge_type[i].item())
        
        # é™åˆ¶è¾¹æ•°é‡
        if len(sampled_edges) > self.max_edges:
            indices = random.sample(range(len(sampled_edges)), self.max_edges)
            sampled_edges = [sampled_edges[i] for i in indices]
            sampled_edge_types = [sampled_edge_types[i] for i in indices]
        
        if sampled_edges:
            sampled_edge_index = torch.tensor(sampled_edges, dtype=torch.long, device=edge_index.device).t()
            sampled_edge_type = torch.tensor(sampled_edge_types, dtype=torch.long, device=edge_type.device)
        else:
            sampled_edge_index = torch.empty(2, 0, dtype=torch.long, device=edge_index.device)
            sampled_edge_type = torch.empty(0, dtype=torch.long, device=edge_type.device)
        
        return sampled_node_features, sampled_edge_index, sampled_edge_type, sampled_nodes_list


class AdaptiveGraphSampler(GraphSampler):
    """
    ğŸš€ è‡ªé€‚åº”å›¾é‡‡æ ·å™¨ - æ ¹æ®å›¾çš„ç‰¹æ€§è‡ªåŠ¨é€‰æ‹©æœ€ä½³é‡‡æ ·ç­–ç•¥
    """
    
    def __init__(self, max_nodes: int = 200, max_edges: int = 500):
        super().__init__(max_nodes, max_edges)
        
    def adaptive_sampling(self,
                         node_features: torch.Tensor,
                         edge_index: torch.Tensor,
                         edge_type: torch.Tensor,
                         query_nodes: List[int] = None) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, List[int]]:
        """
        ğŸš€ è‡ªé€‚åº”é‡‡æ · - æ ¹æ®å›¾çš„ç‰¹æ€§é€‰æ‹©æœ€ä½³ç­–ç•¥
        Args:
            node_features: èŠ‚ç‚¹ç‰¹å¾
            edge_index: è¾¹ç´¢å¼•
            edge_type: è¾¹ç±»å‹
            query_nodes: æŸ¥è¯¢ç›¸å…³çš„èŠ‚ç‚¹ï¼ˆå¯é€‰ï¼‰
        Returns:
            é‡‡æ ·åçš„å­å›¾ç»„ä»¶
        """
        num_nodes = node_features.size(0)
        num_edges = edge_index.size(1)
        
        if num_nodes <= self.max_nodes:
            return node_features, edge_index, edge_type, list(range(num_nodes))
        
        # è®¡ç®—å›¾çš„å¯†åº¦
        max_possible_edges = num_nodes * (num_nodes - 1) // 2
        density = num_edges / max_possible_edges if max_possible_edges > 0 else 0
        
        # è®¡ç®—å¹³å‡åº¦
        avg_degree = (2 * num_edges) / num_nodes if num_nodes > 0 else 0
        
        # æ ¹æ®å›¾ç‰¹æ€§é€‰æ‹©é‡‡æ ·ç­–ç•¥
        if query_nodes and len(query_nodes) > 0:
            # æœ‰æŸ¥è¯¢èŠ‚ç‚¹æ—¶ï¼Œä½¿ç”¨Kè·³é‡‡æ ·
            if avg_degree > 10:  # é«˜åº¦è¿æ¥çš„å›¾
                return self.k_hop_sampling(node_features, edge_index, edge_type, query_nodes, k=1)
            else:  # ç¨€ç–å›¾
                return self.k_hop_sampling(node_features, edge_index, edge_type, query_nodes, k=2)
        
        elif density > 0.1:  # å¯†é›†å›¾
            # ä½¿ç”¨éšæœºæ¸¸èµ°é‡‡æ ·
            start_nodes = random.sample(range(num_nodes), min(5, num_nodes))
            return self.random_walk_sampling(node_features, edge_index, edge_type, start_nodes, walk_length=3, num_walks=5)
        
        else:  # ç¨€ç–å›¾
            # ä½¿ç”¨æ›´é•¿çš„éšæœºæ¸¸èµ°
            start_nodes = random.sample(range(num_nodes), min(3, num_nodes))
            return self.random_walk_sampling(node_features, edge_index, edge_type, start_nodes, walk_length=5, num_walks=8)
