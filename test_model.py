#!/usr/bin/env python3
"""
Quick test script to verify model functionality.
"""

import torch
import json
import os
from src.model import GDMNet
from src.dataloader import HotpotQADataset, GDMNetDataCollator
from src.utils import load_config
from torch.utils.data import DataLoader

# Set environment variables for Chinese mirror
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
os.environ['HUGGINGFACE_HUB_CACHE'] = '/tmp/huggingface_cache'


def test_model_forward():
    """Test model forward pass with detailed debugging."""
    print("Testing model forward pass...")

    try:
        # Load config
        config = load_config('config/default_config.yaml')
        print(f"  Config hidden_size: {config['model']['hidden_size']}")

        # Initialize model components step by step
        print("  Initializing DocumentEncoder...")
        from src.model.bert_encoder import DocumentEncoder
        doc_encoder = DocumentEncoder(
            model_name=config['model']['bert_model_name'],
            hidden_size=config['model']['hidden_size']
        )
        print(f"    BERT config hidden_size: {doc_encoder.config.hidden_size}")
        print(f"    Target hidden_size: {doc_encoder.hidden_size}")
        print(f"    Need projection: {doc_encoder.need_projection}")
        print(f"    BERT model type: {type(doc_encoder.bert).__name__}")

        # Test document encoding
        batch_size = 2
        seq_len = 128
        dummy_input_ids = torch.randint(1, 1000, (batch_size, seq_len))
        dummy_attention_mask = torch.ones(batch_size, seq_len)

        print("  Testing document encoding...")
        doc_pooled, doc_sequence = doc_encoder.encode_document(dummy_input_ids, dummy_attention_mask)
        print(f"    doc_pooled shape: {doc_pooled.shape}")
        print(f"    doc_sequence shape: {doc_sequence.shape}")

        # Test structure extraction
        print("  Testing structure extraction...")
        from src.model.bert_encoder import StructureExtractor
        struct_extractor = StructureExtractor(
            hidden_size=config['model']['hidden_size'],
            num_entity_types=config['model']['num_entities'],
            num_relation_types=config['model']['num_relations']
        )

        num_entities = config['model']['num_entities']
        entity_spans = torch.zeros(batch_size, num_entities, 2, dtype=torch.long)
        for b in range(batch_size):
            for e in range(num_entities):
                start = torch.randint(0, seq_len - 10, (1,)).item()
                end = start + torch.randint(1, 10, (1,)).item()
                entity_spans[b, e] = torch.tensor([start, min(end, seq_len - 1)])

        entity_logits, relation_logits, entities_batch, relations_batch = struct_extractor(
            doc_sequence, dummy_attention_mask, entity_spans
        )
        print(f"    entity_logits shape: {entity_logits.shape}")
        print(f"    entities_batch length: {len(entities_batch)}")
        for i, entities in enumerate(entities_batch):
            print(f"      Batch {i}: {len(entities)} entities")
            for j, entity in enumerate(entities[:3]):  # Show first 3 entities
                print(f"        Entity {j}: type={entity['type']}, span={entity['span']}, repr_shape={entity['representation'].shape}")

        # Test graph writer
        print("  Testing graph writer...")
        from src.model.graph_memory import GraphWriter
        graph_writer = GraphWriter(
            hidden_size=config['model']['hidden_size'],
            num_entity_types=config['model']['num_entities'],
            num_relation_types=config['model']['num_relations']
        )

        node_features, edge_index, edge_type, batch_indices = graph_writer(
            entities_batch, relations_batch, doc_sequence
        )
        print(f"    node_features shape: {node_features.shape}")
        print(f"    edge_index shape: {edge_index.shape}")
        print(f"    edge_type shape: {edge_type.shape}")
        print(f"    batch_indices shape: {batch_indices.shape}")

        # Test full model with detailed intermediate results
        print("  Testing full model with intermediate results...")
        model = GDMNet(**config['model'])
        model.eval()

        dummy_batch = {
            'query_input_ids': torch.randint(1, 1000, (batch_size, 64)),
            'query_attention_mask': torch.ones(batch_size, 64),
            'doc_input_ids': dummy_input_ids,
            'doc_attention_mask': dummy_attention_mask,
            'entity_spans': entity_spans,
            'labels': torch.randint(0, config['model']['num_classes'], (batch_size,))
        }

        # Forward pass with detailed outputs
        with torch.no_grad():
            outputs = model(**dummy_batch)

        print(f"\nğŸ¯ GDM-Net åŒè·¯å¾„å¤„ç†ç»“æœå±•ç¤º:")
        print(f"=" * 60)

        # 1. éšå¼è·¯å¾„ (Implicit Path) - BERTæ–‡æ¡£ç¼–ç 
        print(f"\nğŸ“„ éšå¼è·¯å¾„ (Implicit Path) - æ–‡æ¡£è¯­ä¹‰è¡¨ç¤º:")
        print(f"  æ–‡æ¡£è¡¨ç¤º (doc_representation): {outputs['doc_representation'].shape}")
        print(f"  æŸ¥è¯¢è¡¨ç¤º (query_representation): {outputs['query_representation'].shape}")
        print(f"  ç‰¹ç‚¹: ç¨ å¯†å‘é‡ï¼ŒåŒ…å«å…¨å±€è¯­ä¹‰ä¿¡æ¯")

        # 2. æ˜¾å¼è·¯å¾„ (Explicit Path) - ç»“æ„åŒ–çŸ¥è¯†
        print(f"\nğŸ”— æ˜¾å¼è·¯å¾„ (Explicit Path) - ç»“æ„åŒ–çŸ¥è¯†è¡¨ç¤º:")
        print(f"  æå–çš„å®ä½“æ•°é‡: {len(outputs['entities_batch'][0])} (batch 0)")
        print(f"  æå–çš„å…³ç³»æ•°é‡: {len(outputs['relations_batch'][0])} (batch 0)")

        # æ˜¾ç¤ºæå–çš„å®ä½“ä¿¡æ¯
        if outputs['entities_batch'][0]:
            print(f"  å®ä½“ç¤ºä¾‹:")
            for i, entity in enumerate(outputs['entities_batch'][0][:3]):  # æ˜¾ç¤ºå‰3ä¸ª
                print(f"    å®ä½“{i+1}: ç±»å‹={entity['type']}, ä½ç½®={entity['span']}")

        # æ˜¾ç¤ºæå–çš„å…³ç³»ä¿¡æ¯
        if outputs['relations_batch'][0]:
            print(f"  å…³ç³»ç¤ºä¾‹:")
            for i, relation in enumerate(outputs['relations_batch'][0][:3]):  # æ˜¾ç¤ºå‰3ä¸ª
                print(f"    å…³ç³»{i+1}: å¤´å®ä½“={relation['head']}, å°¾å®ä½“={relation['tail']}, ç±»å‹={relation['type']}")

        # 3. å›¾è¡¨ç¤º
        print(f"\nğŸ•¸ï¸  å›¾ç¥ç»ç½‘ç»œå¤„ç†ç»“æœ:")
        print(f"  å›¾è¡¨ç¤º (graph_representation): {outputs['graph_representation'].shape}")
        print(f"  ç‰¹ç‚¹: ç»è¿‡GNNå¤„ç†çš„ç»“æ„åŒ–çŸ¥è¯†è¡¨ç¤º")

        # 4. å¤šè·³æ¨ç†è·¯å¾„
        print(f"\nğŸ”„ å¤šè·³æ¨ç†è·¯å¾„:")
        print(f"  è·¯å¾„è¡¨ç¤º (path_representation): {outputs['path_representation'].shape}")
        print(f"  ç‰¹ç‚¹: åŸºäºæŸ¥è¯¢çš„å¤šè·³æ¨ç†ç»“æœ")

        # 5. åŒè®°å¿†ç³»ç»Ÿ
        print(f"\nğŸ§  åŒè®°å¿†ç³»ç»Ÿ:")
        print(f"  è®°å¿†è¾“å‡º (memory_output): {outputs['memory_output'].shape}")
        print(f"  ç‰¹ç‚¹: æƒ…èŠ‚è®°å¿† + è¯­ä¹‰è®°å¿†çš„èåˆ")

        # 6. æœ€ç»ˆèåˆ
        print(f"\nâš¡ åŒè·¯å¾„èåˆç»“æœ:")
        print(f"  èåˆè¡¨ç¤º (fused_representation): {outputs['fused_representation'].shape}")
        print(f"  æœ€ç»ˆåˆ†ç±» (logits): {outputs['logits'].shape}")
        print(f"  é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ:")
        probs = torch.softmax(outputs['logits'], dim=1)
        for i in range(min(2, batch_size)):  # æ˜¾ç¤ºå‰2ä¸ªæ ·æœ¬
            print(f"    æ ·æœ¬{i+1}: {[f'{p:.3f}' for p in probs[i].tolist()]}")

        # 7. åˆ›æ–°ç‚¹æ€»ç»“
        print(f"\nğŸŒŸ GDM-Net åˆ›æ–°ç‚¹å±•ç¤º:")
        print(f"  âœ… åŒè·¯å¾„å¤„ç†: éšå¼(BERT) + æ˜¾å¼(å›¾ç»“æ„)")
        print(f"  âœ… åŠ¨æ€å›¾æ„å»º: ä»æ–‡æœ¬è‡ªåŠ¨æå–å®ä½“å…³ç³»")
        print(f"  âœ… å¤šè·³æ¨ç†: PathFinderè¿›è¡Œæ¨ç†è·¯å¾„å‘ç°")
        print(f"  âœ… å›¾è¯»å–æœºåˆ¶: GraphReaderåŸºäºæŸ¥è¯¢è¯»å–å›¾ä¿¡æ¯")
        print(f"  âœ… æ™ºèƒ½èåˆ: å¤šç§è¡¨ç¤ºçš„è‡ªé€‚åº”èåˆ")
        print(f"  âœ… ç«¯åˆ°ç«¯è®­ç»ƒ: ä¸»ä»»åŠ¡+è¾…åŠ©ä»»åŠ¡è”åˆä¼˜åŒ–")

        print(f"\nâœ“ Model forward pass successful")
        print(f"  Output logits shape: {outputs['logits'].shape}")
        print(f"  Expected shape: ({batch_size}, {config['model']['num_classes']})")

        return True

    except Exception as e:
        import traceback
        print(f"âœ— Model forward pass failed: {str(e)}")
        print("  Full traceback:")
        traceback.print_exc()
        return False


def test_dataset_loading():
    """Test dataset loading and check data structure."""
    print("\nTesting dataset loading...")

    # Load config
    config = load_config('config/default_config.yaml')

    # First, check raw data structure
    import json
    print("  Checking raw data structure...")
    try:
        with open(config['data']['train_path'], 'r', encoding='utf-8') as f:
            raw_data = json.load(f)

        print(f"  Raw data type: {type(raw_data)}")
        print(f"  Raw data length: {len(raw_data)}")

        # Check first sample structure
        first_sample = raw_data[0]
        print(f"  First sample keys: {list(first_sample.keys())}")

        # Check if there's a label field
        if 'label' in first_sample:
            print(f"  Label field exists: {first_sample['label']}")
        elif 'answer' in first_sample:
            print(f"  Answer field exists: {first_sample['answer']}")
        else:
            print(f"  No obvious label field. Available keys: {list(first_sample.keys())}")

        # Check a few samples for label distribution
        labels_found = []
        for i in range(min(10, len(raw_data))):
            sample = raw_data[i]
            if 'label' in sample:
                labels_found.append(sample['label'])
            elif 'answer' in sample:
                labels_found.append(sample['answer'])

        print(f"  Labels in first 10 samples: {labels_found}")

    except Exception as e:
        print(f"  Error reading raw data: {e}")

    # Test with dataset class
    try:
        dataset = HotpotQADataset(
            data_path=config['data']['train_path'],
            tokenizer_name=config['model']['bert_model_name'],
            max_length=config['data']['max_length'],
            max_query_length=config['data']['max_query_length'],
            num_entities=config['model']['num_entities']
        )

        print(f"âœ“ Dataset loaded successfully")
        print(f"  Dataset size: {len(dataset)}")

        # Test single sample
        sample = dataset[0]
        print(f"  Sample keys: {list(sample.keys())}")
        print(f"  Label value: {sample['label']}")
        print(f"  Label type: {type(sample['label'])}")

        # Check label distribution
        label_dist = dataset.get_label_distribution()
        print(f"  Label distribution: {label_dist}")

        # Test dataloader
        collator = GDMNetDataCollator()
        dataloader = DataLoader(
            dataset,
            batch_size=2,
            shuffle=False,
            collate_fn=collator
        )

        batch = next(iter(dataloader))
        print(f"  Batch keys: {list(batch.keys())}")
        print(f"  Batch size: {batch['labels'].shape[0]}")
        print(f"  Batch labels: {batch['labels']}")
        print(f"  Labels range: [{batch['labels'].min()}, {batch['labels'].max()}]")

        return True

    except Exception as e:
        print(f"âœ— Dataset loading failed: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def test_training_step():
    """Test a single training step."""
    print("\nTesting training step...")
    
    try:
        from src.train import GDMNetTrainer
        
        # Load config
        config = load_config('config/default_config.yaml')
        
        # Initialize trainer
        trainer = GDMNetTrainer(config)
        trainer.eval()
        
        # Create dummy batch (same as in test_model_forward)
        batch_size = 2
        seq_len = 128
        num_entities = config['model']['num_entities']
        
        # Create valid entity spans
        entity_spans = torch.zeros(batch_size, num_entities, 2, dtype=torch.long)
        for b in range(batch_size):
            for e in range(num_entities):
                start = torch.randint(0, seq_len - 10, (1,)).item()
                end = start + torch.randint(1, 10, (1,)).item()
                entity_spans[b, e] = torch.tensor([start, min(end, seq_len - 1)])

        dummy_batch = {
            'query_input_ids': torch.randint(1, 1000, (batch_size, 64)),
            'query_attention_mask': torch.ones(batch_size, 64),
            'doc_input_ids': torch.randint(1, 1000, (batch_size, seq_len)),
            'doc_attention_mask': torch.ones(batch_size, seq_len),
            'entity_spans': entity_spans,
            'labels': torch.randint(0, config['model']['num_classes'], (batch_size,))
        }
        
        # Test training step
        with torch.no_grad():
            outputs = trainer.forward(dummy_batch)
            loss_dict = trainer.model.compute_loss(outputs, dummy_batch['labels'])
            loss = loss_dict['total_loss']

        print(f"âœ“ Training step successful")
        print(f"  Loss: {loss.item():.4f}")

        return True

    except Exception as e:
        import traceback
        print(f"âœ— Training step failed: {str(e)}")
        print("  Full traceback:")
        traceback.print_exc()
        return False


def test_intermediate_results():
    """ä¸“é—¨æµ‹è¯•å’Œå±•ç¤ºGDM-Netçš„ä¸­é—´ç»“æœ"""
    print("\nğŸ”¬ GDM-Net ä¸­é—´ç»“æœè¯¦ç»†åˆ†æ")
    print("=" * 80)

    try:
        # Load config
        config = load_config('config/default_config.yaml')

        # Initialize model
        model = GDMNet(**config['model'])
        model.eval()

        # Create a more realistic test batch
        batch_size = 1  # ä½¿ç”¨å•ä¸ªæ ·æœ¬ä¾¿äºåˆ†æ
        seq_len = 128

        # æ¨¡æ‹ŸçœŸå®çš„è¾“å…¥æ•°æ®
        dummy_batch = {
            'query_input_ids': torch.randint(1, 1000, (batch_size, 64)),
            'query_attention_mask': torch.ones(batch_size, 64),
            'doc_input_ids': torch.randint(1, 1000, (batch_size, seq_len)),
            'doc_attention_mask': torch.ones(batch_size, seq_len),
            'entity_spans': torch.tensor([[[10, 15], [25, 30], [45, 50], [60, 65], [80, 85], [90, 95], [100, 105], [110, 115], [120, 125]]]),
            'labels': torch.randint(0, config['model']['num_classes'], (batch_size,))
        }

        # Forward pass
        with torch.no_grad():
            outputs = model(**dummy_batch)

        print("\nğŸ“Š GDM-Net åŒè·¯å¾„å¤„ç†æµç¨‹åˆ†æ:")
        print("-" * 60)
        print("ğŸ¯ è¿™æ˜¯GDM-Netçš„æ ¸å¿ƒåˆ›æ–°ç‚¹å±•ç¤º!")

        # 1. è¾“å…¥åˆ†æ
        print(f"ğŸ“¥ è¾“å…¥æ•°æ®:")
        print(f"  æŸ¥è¯¢é•¿åº¦: {dummy_batch['query_input_ids'].shape[1]}")
        print(f"  æ–‡æ¡£é•¿åº¦: {dummy_batch['doc_input_ids'].shape[1]}")
        print(f"  å®ä½“spanæ•°é‡: {dummy_batch['entity_spans'].shape[1]}")

        # 2. éšå¼è·¯å¾„åˆ†æ
        print(f"\nğŸ”„ éšå¼è·¯å¾„ (BERTç¼–ç ):")
        doc_repr = outputs['doc_representation']
        query_repr = outputs['query_representation']
        print(f"  æ–‡æ¡£è¡¨ç¤ºç»´åº¦: {doc_repr.shape}")
        print(f"  æ–‡æ¡£è¡¨ç¤ºç»Ÿè®¡: min={doc_repr.min():.3f}, max={doc_repr.max():.3f}, mean={doc_repr.mean():.3f}")
        print(f"  æŸ¥è¯¢è¡¨ç¤ºç»´åº¦: {query_repr.shape}")
        print(f"  æŸ¥è¯¢è¡¨ç¤ºç»Ÿè®¡: min={query_repr.min():.3f}, max={query_repr.max():.3f}, mean={query_repr.mean():.3f}")

        # 3. æ˜¾å¼è·¯å¾„åˆ†æ
        print(f"\nğŸ•¸ï¸  æ˜¾å¼è·¯å¾„ (ç»“æ„åŒ–çŸ¥è¯†):")
        entities = outputs['entities_batch'][0]
        relations = outputs['relations_batch'][0]
        print(f"  æå–å®ä½“æ•°é‡: {len(entities)}")
        print(f"  æå–å…³ç³»æ•°é‡: {len(relations)}")

        if entities:
            entity_types = [e['type'] for e in entities]
            print(f"  å®ä½“ç±»å‹åˆ†å¸ƒ: {dict(zip(*torch.unique(torch.tensor(entity_types), return_counts=True)))}")

        if relations:
            relation_types = [r['type'] for r in relations]
            print(f"  å…³ç³»ç±»å‹åˆ†å¸ƒ: {dict(zip(*torch.unique(torch.tensor(relation_types), return_counts=True)))}")

        # 4. å›¾æ„å»ºåˆ†æ
        print(f"\nğŸ”— å›¾æ„å»ºç»“æœ:")
        print(f"  èŠ‚ç‚¹æ•°é‡: {outputs['node_features'].shape[0]}")
        print(f"  è¾¹æ•°é‡: {outputs['edge_index'].shape[1]}")
        print(f"  èŠ‚ç‚¹ç‰¹å¾ç»´åº¦: {outputs['node_features'].shape[1]}")
        print(f"  è¾¹ç±»å‹æ•°é‡: {len(torch.unique(outputs['edge_type']))}")

        # 5. å›¾ç¥ç»ç½‘ç»œå¤„ç†
        print(f"\nğŸ§  å›¾ç¥ç»ç½‘ç»œå¤„ç†:")
        updated_features = outputs['updated_node_features']
        print(f"  æ›´æ–°åèŠ‚ç‚¹ç‰¹å¾: {updated_features.shape}")
        print(f"  ç‰¹å¾å˜åŒ–ç»Ÿè®¡: min={updated_features.min():.3f}, max={updated_features.max():.3f}")

        # 6. æ¨ç†æ¨¡å—åˆ†æ
        print(f"\nğŸ” æ¨ç†æ¨¡å—ç»“æœ:")
        graph_repr = outputs['graph_representation']
        path_repr = outputs['path_representation']
        print(f"  å›¾è¡¨ç¤º: {graph_repr.shape}")
        print(f"  è·¯å¾„è¡¨ç¤º: {path_repr.shape}")
        print(f"  å›¾è¡¨ç¤ºç»Ÿè®¡: min={graph_repr.min():.3f}, max={graph_repr.max():.3f}")
        print(f"  è·¯å¾„è¡¨ç¤ºç»Ÿè®¡: min={path_repr.min():.3f}, max={path_repr.max():.3f}")

        # 7. è®°å¿†ç³»ç»Ÿåˆ†æ
        print(f"\nğŸ’­ åŒè®°å¿†ç³»ç»Ÿ:")
        memory_out = outputs['memory_output']
        episodic_out = outputs['episodic_output']
        semantic_out = outputs['semantic_output']
        print(f"  è®°å¿†è¾“å‡º: {memory_out.shape}")
        print(f"  æƒ…èŠ‚è®°å¿†: {episodic_out.shape}")
        print(f"  è¯­ä¹‰è®°å¿†: {semantic_out.shape}")

        # 8. æœ€ç»ˆèåˆåˆ†æ
        print(f"\nâš¡ æœ€ç»ˆèåˆ:")
        fused_repr = outputs['fused_representation']
        logits = outputs['logits']
        print(f"  èåˆè¡¨ç¤º: {fused_repr.shape}")
        print(f"  åˆ†ç±»logits: {logits.shape}")

        # 9. é¢„æµ‹ç»“æœ
        probs = torch.softmax(logits, dim=1)
        pred_class = torch.argmax(logits, dim=1)
        print(f"\nğŸ¯ é¢„æµ‹ç»“æœ:")
        print(f"  é¢„æµ‹ç±»åˆ«: {pred_class.item()}")
        print(f"  ç½®ä¿¡åº¦åˆ†å¸ƒ: {[f'{p:.3f}' for p in probs[0].tolist()]}")
        print(f"  æœ€é«˜ç½®ä¿¡åº¦: {probs.max().item():.3f}")

        # 10. åˆ›æ–°ç‚¹æ€»ç»“
        print(f"\nğŸŒŸ GDM-Net åˆ›æ–°ç‚¹éªŒè¯:")
        print(f"  âœ… åŒè·¯å¾„å¤„ç†: éšå¼({doc_repr.shape}) + æ˜¾å¼({len(entities)}å®ä½“, {len(relations)}å…³ç³»)")
        print(f"  âœ… åŠ¨æ€å›¾æ„å»º: {outputs['node_features'].shape[0]}èŠ‚ç‚¹, {outputs['edge_index'].shape[1]}è¾¹")
        print(f"  âœ… å¤šè·³æ¨ç†: è·¯å¾„å‘ç°({path_repr.shape}) + å›¾è¯»å–({graph_repr.shape})")
        print(f"  âœ… è®°å¿†èåˆ: æƒ…èŠ‚+è¯­ä¹‰â†’è®°å¿†è¾“å‡º({memory_out.shape})")
        print(f"  âœ… æ™ºèƒ½èåˆ: æ–‡æ¡£+å›¾+è·¯å¾„+è®°å¿†â†’æœ€ç»ˆè¡¨ç¤º({fused_repr.shape})")

        return True

    except Exception as e:
        print(f"âœ— ä¸­é—´ç»“æœæµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """Run all tests."""
    print("=" * 50)
    print("GDM-Net Model Testing")
    print("=" * 50)

    tests = [
        test_model_forward,
        test_dataset_loading,
        test_training_step,
        test_intermediate_results  # æ·»åŠ ä¸­é—´ç»“æœå±•ç¤º
    ]
    
    passed = 0
    total = len(tests)
    
    for test in tests:
        try:
            if test():
                passed += 1
        except Exception as e:
            print(f"âœ— Test failed with exception: {str(e)}")
    
    print("\n" + "=" * 50)
    print(f"Test Results: {passed}/{total} tests passed")
    print("=" * 50)
    
    if passed == total:
        print("ğŸ‰ All tests passed! Model is ready for training.")
    else:
        print("âš ï¸  Some tests failed. Please check the errors above.")
    
    return passed == total


if __name__ == "__main__":
    main()
