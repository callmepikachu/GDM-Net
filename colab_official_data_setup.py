"""
Google Colab å®˜æ–¹HotpotQAæ•°æ®é›†é…ç½®è„šæœ¬
ä¸“é—¨ä¸ºä½¿ç”¨å®˜æ–¹æ•°æ®é›†ä¼˜åŒ–çš„é…ç½®
"""

import json
import os
import yaml


def check_official_data():
    """æ£€æŸ¥å®˜æ–¹æ•°æ®æ–‡ä»¶"""
    print("ğŸ” æ£€æŸ¥å®˜æ–¹HotpotQAæ•°æ®é›†...")
    
    data_files = [
        'data/hotpotqa_official_train.json',
        'data/hotpotqa_official_val.json'
    ]
    
    all_exist = True
    total_samples = 0
    
    for file_path in data_files:
        if os.path.exists(file_path):
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            print(f"âœ… {file_path}: {len(data)} æ ·æœ¬")
            total_samples += len(data)
            
            # æ˜¾ç¤ºçœŸå®çš„å®˜æ–¹æ•°æ®æ ·æœ¬
            if data:
                sample = data[0]
                print(f"   æ–‡æ¡£: {sample['document'][:100]}...")
                print(f"   æŸ¥è¯¢: {sample['query']}")
                print(f"   å®ä½“: {len(sample['entities'])}, å…³ç³»: {len(sample['relations'])}")
                print(f"   ç­”æ¡ˆ: {sample['metadata'].get('answer', 'N/A')}")
                print()
        else:
            print(f"âŒ {file_path}: æ–‡ä»¶ä¸å­˜åœ¨")
            all_exist = False
    
    if all_exist:
        print(f"ğŸ‰ å®˜æ–¹æ•°æ®é›†æ£€æŸ¥å®Œæˆï¼æ€»è®¡ {total_samples} æ ·æœ¬")
        return True
    else:
        print("âŒ ç¼ºå°‘å®˜æ–¹æ•°æ®æ–‡ä»¶")
        return False


def create_official_data_config():
    """åˆ›å»ºé’ˆå¯¹å®˜æ–¹æ•°æ®ä¼˜åŒ–çš„é…ç½®"""
    print("âš™ï¸ åˆ›å»ºå®˜æ–¹æ•°æ®é…ç½®...")
    
    # é’ˆå¯¹å®˜æ–¹HotpotQAæ•°æ®çš„ä¼˜åŒ–é…ç½®
    config = {
        'seed': 42,
        'model': {
            'bert_model_name': 'bert-base-uncased',
            'hidden_size': 768,
            'num_entities': 8,  # å®˜æ–¹æ•°æ®ä¸­çš„å®ä½“ç±»å‹æ•°
            'num_relations': 4,  # å®˜æ–¹æ•°æ®ä¸­çš„å…³ç³»ç±»å‹æ•°
            'num_classes': 5,    # å®˜æ–¹æ•°æ®ä¸­çš„æ ‡ç­¾ç±»åˆ«æ•°
            'gnn_type': 'rgcn',
            'num_gnn_layers': 2,
            'num_reasoning_hops': 3,  # é€‚åˆå¤šè·³æ¨ç†
            'fusion_method': 'gate',
            'learning_rate': 2e-5,
            'dropout_rate': 0.1
        },
        'data': {
            'train_path': 'data/hotpotqa_official_train.json',
            'val_path': 'data/hotpotqa_official_val.json', 
            'test_path': 'data/hotpotqa_official_val.json',
            'max_length': 512,  # å®˜æ–¹æ•°æ®éœ€è¦æ›´é•¿çš„åºåˆ—
            'max_query_length': 64
        },
        'training': {
            'max_epochs': 10,
            'batch_size': 4,  # å®˜æ–¹æ•°æ®æ›´å¤æ‚ï¼Œå‡å°‘batch size
            'num_workers': 2,
            'accelerator': 'gpu',
            'devices': 1,
            'precision': 16,  # æ··åˆç²¾åº¦èŠ‚çœå†…å­˜
            'gradient_clip_val': 1.0,
            'accumulate_grad_batches': 2,  # æ¢¯åº¦ç´¯ç§¯è¡¥å¿å°batch size
            'val_check_interval': 0.25,  # æ›´é¢‘ç¹çš„éªŒè¯
            'log_every_n_steps': 25,
            'checkpoint_dir': 'checkpoints',
            'early_stopping': True,
            'patience': 3
        },
        'logging': {
            'type': 'tensorboard',
            'save_dir': 'logs',
            'name': 'gdmnet-official-hotpotqa'
        }
    }
    
    # ä¿å­˜é…ç½®
    with open('config/official_hotpotqa_config.yaml', 'w') as f:
        yaml.dump(config, f, default_flow_style=False)
    
    print("âœ… å®˜æ–¹æ•°æ®é…ç½®: config/official_hotpotqa_config.yaml")
    return config


def analyze_official_data():
    """åˆ†æå®˜æ–¹æ•°æ®çš„ç‰¹å¾"""
    print("ğŸ“Š åˆ†æå®˜æ–¹æ•°æ®ç‰¹å¾...")
    
    if not os.path.exists('data/hotpotqa_official_train.json'):
        print("âŒ è®­ç»ƒæ•°æ®ä¸å­˜åœ¨")
        return
    
    with open('data/hotpotqa_official_train.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # ç»Ÿè®¡åˆ†æ
    doc_lengths = []
    query_lengths = []
    entity_counts = []
    relation_counts = []
    label_counts = {}
    
    for item in data:
        doc_lengths.append(len(item['document']))
        query_lengths.append(len(item['query']))
        entity_counts.append(len(item['entities']))
        relation_counts.append(len(item['relations']))
        
        label = item['label']
        label_counts[label] = label_counts.get(label, 0) + 1
    
    print(f"ğŸ“‹ æ•°æ®ç»Ÿè®¡:")
    print(f"   æ ·æœ¬æ•°é‡: {len(data)}")
    print(f"   å¹³å‡æ–‡æ¡£é•¿åº¦: {sum(doc_lengths)/len(doc_lengths):.0f} å­—ç¬¦")
    print(f"   å¹³å‡æŸ¥è¯¢é•¿åº¦: {sum(query_lengths)/len(query_lengths):.0f} å­—ç¬¦")
    print(f"   å¹³å‡å®ä½“æ•°: {sum(entity_counts)/len(entity_counts):.1f}")
    print(f"   å¹³å‡å…³ç³»æ•°: {sum(relation_counts)/len(relation_counts):.1f}")
    print(f"   æ ‡ç­¾åˆ†å¸ƒ: {label_counts}")
    
    # æ¨èé…ç½®
    max_doc_len = max(doc_lengths)
    max_query_len = max(query_lengths)
    
    print(f"\nğŸ’¡ æ¨èé…ç½®:")
    print(f"   max_length: {min(512, max_doc_len + 50)}")
    print(f"   max_query_length: {min(64, max_query_len + 10)}")
    print(f"   batch_size: 4 (GPU) æˆ– 2 (å†…å­˜ä¸è¶³æ—¶)")


def create_training_script():
    """åˆ›å»ºå®˜æ–¹æ•°æ®è®­ç»ƒè„šæœ¬"""
    print("ğŸ“ åˆ›å»ºè®­ç»ƒè„šæœ¬...")
    
    training_script = '''
# å®˜æ–¹HotpotQAæ•°æ®é›†è®­ç»ƒè„šæœ¬

# 1. æ£€æŸ¥ç¯å¢ƒ
import torch
print(f"CUDA available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"GPU: {torch.cuda.get_device_name(0)}")

# 2. è®¾ç½®ç¯å¢ƒå˜é‡
import os
os.environ['TOKENIZERS_PARALLELISM'] = 'false'

# 3. å¼€å§‹è®­ç»ƒ
print("ğŸš€ å¼€å§‹å®˜æ–¹HotpotQAæ•°æ®é›†è®­ç»ƒ...")
!python train/train.py --config config/official_hotpotqa_config.yaml --mode train

# 4. å¯åŠ¨TensorBoardç›‘æ§
%load_ext tensorboard
%tensorboard --logdir logs/

print("âœ… è®­ç»ƒå¯åŠ¨å®Œæˆï¼")
'''
    
    with open('train_official_hotpotqa.py', 'w') as f:
        f.write(training_script.strip())
    
    print("âœ… è®­ç»ƒè„šæœ¬: train_official_hotpotqa.py")


def show_colab_instructions():
    """æ˜¾ç¤ºColabä½¿ç”¨è¯´æ˜"""
    print("\nğŸ¯ Google Colab ä½¿ç”¨è¯´æ˜")
    print("=" * 50)
    
    print("ğŸ“‹ åœ¨Colabä¸­æ‰§è¡Œä»¥ä¸‹æ­¥éª¤:")
    print()
    print("1. ğŸ”§ è¿è¡Œç¯å¢ƒè®¾ç½®:")
    print("   !python colab_official_data_setup.py")
    print()
    print("2. ğŸ‹ï¸ å¼€å§‹è®­ç»ƒ:")
    print("   !python train/train.py --config config/official_hotpotqa_config.yaml --mode train")
    print()
    print("3. ğŸ“Š ç›‘æ§è®­ç»ƒ:")
    print("   %load_ext tensorboard")
    print("   %tensorboard --logdir logs/")
    print()
    print("4. ğŸ’¾ ä¿å­˜ç»“æœåˆ°Drive:")
    print("   !cp -r checkpoints/* /content/drive/MyDrive/GDM-Net-Results/")
    print("   !cp -r logs/* /content/drive/MyDrive/GDM-Net-Results/")
    print()
    
    print("ğŸ¯ é¢„æœŸæ€§èƒ½ (å®˜æ–¹æ•°æ®):")
    print("   - è®­ç»ƒæ—¶é—´: 2-4å°æ—¶ (T4 GPU)")
    print("   - å†…å­˜ä½¿ç”¨: 6-8GB GPU")
    print("   - é¢„æœŸå‡†ç¡®ç‡: 55-65%")
    print("   - æ¨¡å‹å¤§å°: ~550MB")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§  GDM-Net å®˜æ–¹HotpotQAæ•°æ®é›† Colabé…ç½®")
    print("=" * 60)
    
    # æ£€æŸ¥å®˜æ–¹æ•°æ®
    if not check_official_data():
        print("âŒ è¯·ç¡®ä¿å®˜æ–¹æ•°æ®æ–‡ä»¶å­˜åœ¨")
        return False
    
    print()
    
    # åˆ†ææ•°æ®ç‰¹å¾
    analyze_official_data()
    print()
    
    # åˆ›å»ºä¼˜åŒ–é…ç½®
    create_official_data_config()
    print()
    
    # åˆ›å»ºè®­ç»ƒè„šæœ¬
    create_training_script()
    print()
    
    # æ˜¾ç¤ºä½¿ç”¨è¯´æ˜
    show_colab_instructions()
    
    print("\nğŸ‰ å®˜æ–¹æ•°æ®é…ç½®å®Œæˆï¼")
    print("ç°åœ¨æ‚¨å¯ä»¥åœ¨Colabä¸Šè®­ç»ƒçœŸæ­£çš„å­¦æœ¯çº§åˆ«GDM-Netæ¨¡å‹äº†ï¼")
    
    return True


if __name__ == "__main__":
    main()
